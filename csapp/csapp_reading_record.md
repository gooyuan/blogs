
## 深入理解计算机操作系统

    Computer Systems - A Programmer's Perspective 
    是时候走一遍了, 有些细节先不深究, 如 float数据, 补码之类
    按顺序读, 太难的, 也先过... 如 处理器体系结构
    主要有个整体的概念, 然后捡感兴趣的章节先读
    优化程序性能, 虚拟内存, 异常控制流, 系统级I/O, 网络编程, 并发编程

## 1. 计算机系统漫游
####  位+上下文
1. 文本文件 和 二进制文件 
2. 上下文, 现在看来没啥疑问, 当初可是怎么都想不明白
3. 看不懂的书, 肯定是积累不够

####  程序
1. 翻译成各种形式的字节码
    > 预处理器 -> 编译器 -> 汇编器 -> 链接器
2. GNU环境 
    * EMACS编辑器, GCC编译器, GDB调试器, 汇编器, 链接器, 处理二进制文件的工具及其他一些部件
    * free
####  编译系统
1. 编译器是如何将代码转换成不同平台的机器语言
2. 优化程序性能
3. 理解链接时出现的错误
4. 避免安全漏洞

####  处理器解释指令 
1. shell 解释可执行程序
2. 系统的硬件组成
- 总线
    * 电子管道
- I/O设备
    * 每个I/O设备都通过一个控制器和适配器与I/O总线相连
    * 控制器和适配器的区别主要在于它们的封装方式
- 主存
    * DRAM (dynamic random access memory)
    * 即内存, 临时存储

- 处理器
    * 核心是一个大小为一个字的存储设备, 程序计数器(PC), 指向主存中的机器指令
    * 指令集架构, 微体系结构
    * 寄存器文件是啥, 存放几百字节, CPU 和 ALU各16个? 跟这还不一样, 专门设计的SRAM, 寄存器堆, 
####  高速缓存
1. 高速缓存 SRAM(static random access memory)
- 高速缓存的局部性原理

####  储存设备
1. 存储器层次结构
- 寄存器 > L1高速缓存 > L2 > L3 > 主存(DRAM, 内存) > 本地二级存储 > 远程二级存储

####  操作系统管理硬件 
1. 抽象概念
- 进程 
    * 对正在运行的程序的一种抽象
    * 上下文切换 
    * 线程
- 虚拟内存 
    * 为每个进程提供一个假象, 即独占地使用主存
    * 每个进程看到的内存都是一致的, 称为虚拟地址空间

- 文件
    * 字节序列, 仅此而已
    * 向应用程序提供了一个统一的视图, 来看待系统中可能含有的所有各式各样的I/O设备

2. 内核
- 内核管理管理进程上下文的切换
- 内核是常驻主存的部分
- 内核不是一个独立的进程, 是系统管理全部进程所用代码和数据结构的集合

####  网络通信
1. 网络也是一种I/O设备
2. 通过网络适配器完成机器间的数据复制 

####  重要主题
1. Amdahl 定律
- 要想显著加速整个系统, 必须提升全系统中相当大的部分的速度 
- 描述了改善任何过程的一般原则
- 整体与部分的关系

2.  并发和并行
- 并发 (concurrency) 是一个通用的概念, 指一个同时具有多个活动的系统
- 并行(parallelism) 指的是用并发来使一个系统运行得更快
- 线程级并发
    * 在一个进程中执行多个控制流
    * 多核处理器
        * 每个核有各自的L1和L2高速缓存器, 共享更高层次的高速缓存
        * 从两个方面提高系统性能
        > 1. 减少了在执行多个任务时模拟并发的需要, (这里的模拟并发, 是分配时间片, 上下文切换的消耗么?)
        2. 可以使应用程序运行得更快, 前提是使用多线程编写
    * 超线程
        * 同时多线程(simultaneous multi-threading)
        * 一个CPU执行多个控制流的技术
- 指令级并行
    * 在较低层次的抽象上, 现代处理器同时执行多条指令
    * 超标量(super-scalar)处理器: 比一个周期一条指令更快的执行效率
    * 单指令, 多数据并行
3. 计算机系统中抽象的重要性
- 提供不同层次的抽象表示, 来隐藏实际实现的复杂性
- |- 虚拟机
    |- 操作系统
    |- 进程
        |- 指令集架构
            |- 处理器
        |- 虚拟内存
            |- 主存
            |- 文件 I/O设备

####  小结

## 2. 信息的表示与处理
#### 信息存储
1. 无符号数, 有符号数, 浮点数
- 溢出
- 补码
- 浮点运算是不可结合的 

2. 信息存储
- 虚拟内存上, 非常大的字节数
- 编译器和运行时系统将存储空间划分为更可管理的单元
- 程序对象: 程序数据, 指令, 控制信息 
- 可移植性的一个方面: 使程序对不同数据类型的确切大小不敏感

3. 寻址和字节顺序
- 大小端
- 最低有效字节, 从左向右开始, 指的就是数字的高低位

4. 布尔代数
- 与, 或, 非, 异或
- 信息论领域
- 布尔环, 长度为w的位向量上的 ^, & 和 ~ 运算时, 会得到一种不同的数学形式
    a & a = a;  a^a = 0;  0^b = b;
- 位向量运算, 分别将向量的每一位进行 与或非运算
- 位向量与集合的表示
    从右向左, 位向量为1的位置, 构成集合
- 掩码 
- 逻辑运算, 移位运算
    * 逻辑右移, 填充0
    * 算术右移, 按高位值填充
    * 左移都是填充0 
    * 约定有符号数都使用算术右移, 无符号数必须是逻辑右移
    * java中 >> 表示算术移位, >>> 表示逻辑移位

#### 整数表示
1. 无符号数编码的唯一性
- 双射
2. 补码编码
- 有符号数 使用 补码形式
- 补码编码的唯一性
    * 跟无符号数的编码一致, 但是高位为符号位
    * 正数的补码跟原码一致, 负数的补码还原, 符号位不变, 其余位取反加1, (这个还原也只是为了方便人工计算值, 机器计算还是直接用补码计算)
    * 这个性质就是在计算过程中发现的, 算不上推理(我比较倾向于推理的结果, 就是得到证明的结果, 而不是靠经验得出来的结果, 这个观念得改一改)
- 补码和反码

3. 有符号数和无符号数之间的转换
- C语言中不管数值信息, 保留位模式信息, 按强转的类型解释
- 补码转无符号数
- 无符号数转补码, 两个操作反过来
- 有符号数与无符号数比较, 默认先将有符号数转换成无符号数, 这样就会出现一些奇怪的现象
    负数比0大
- INT_MIN 和 INT_MAX
    * #define INT_MIN  (-INT_MAX - 1)

4. 扩展一个数字的位表示
- 无符号数的零扩展
- 补码数的符号扩展
- 截断无符号数 与 截断补码数值

5. 注意事项
- 比较, 数传运算, 避免使用无符号数
- 无符号数可做位的集合, 没有任何数字意义时, 比较好用, 用作mask 

#### 整数运算
1. 正溢出, 负溢出
2. 加, 乘
#### 浮点数
#### 小结
1. 数据表示后续有需求再研究

## 3. 程序的机器级表示
#### 历史观点
1. IA32, X86-64(X86), i386, i486, 
2. K(10^3), M(10^6), G(10^9)
#### 程序编码
1. 机器级代码 
- ISA(Instruction Set Architecture), 指令集架构
- 程序计数器(PC) %rip 给出要执行的下一条指令在内存中的地址
- C语言中的数据类型, 在机器代码中用一组连续的字节来表示, 不区分有无符号, 指针类型, 指针和整数
- x86-64的指令长度从1到15个字节不等, 常用的字节少, 不常用的字节多
- 反汇编器, 直接根据机器指令码序列来确定汇编代码, 与GCC编译出来的有差译, 但是不影响阅读
- ATT(AT&T) 与 Intel 汇编代码格式
    默认使用 ATT, Intel的编码代码比对学习, 多位操作数, 顺序不一致
- 

#### 数据格式
1.  汇编代码后缀
- 字节:b, 字:w, 双字:l, 四字:q, 单精度:s, 双精度:l
    双字和双精度都是l, 不会产生歧义, 因为机器指令和寄存器不同

#### 访问信息
1. 通用目的寄存器
- 16位(%ax-%bp), 32位(%eax-%ebp), 64位(%rax-%rbp, %r8-%r15)
2. 操作数指示符
- 立即数 ($), 寄存器(R[ra]), 内存引用(Mb[Addr])
- 寻址模式: 立即数(Imm), 寄存器(rb), 绝对, 间接, 基址+偏移量, 变址(Imm + R[rb] + R[ri]), 比例变址
- 数据传送指令: mov, 内存/寄存器 -> 寄存器, 目的大于源
    * 零扩展数据传送指令 zbw, zbl, zwl, zbq, zwq
    * 符号扩展数据传送指令 sbw, sbl, swl, sbq, slq, cltq
- 压入和弹出栈数据
    pushq
    popq
#### 算数和逻辑操作
0. 操作数
- 立即数, 寄存器, 内存地址
- 立即数不可作为目的操作数
- 内存地址作为目的操作数时, 处理器必须从内存读出值, 执行操作, 再将结果写回内存

1. 加载有效地址
- leaq S,D 
    D <- &S
    目的操作数必须是一个寄存器
    movq 的变形, 但是并没有引用内存, 而是直接将有效地址写入目的操作数(相当于指针级别的操作咯)

2. 一元操作
- INC D
- DEC D
- NEG D
- NOT D

3. 二元操作
- ADD S, D
    D <- D+S

- SUB, IMUL, XOR, OR, AND
    同上
    imul 两个操作数时, 64位乘积, 一个操作数时, 128位乘积, %rdx 高64位, %rax 低64位
    
- 第二个操作数同时作为目的操作数

4. 移位
- SAL k,D 
    D <- D << k
- SHL, 等同于 SAL
- SAR k,D
    算术右移
- SHR k,d 
    逻辑右移
- 目的操作数为 立即数或寄存器
    寄存器只能使用 %cl
    salb 移7位, salw 移15位, sall 移31位, salq 移63位

#### 控制
> 已知什么
    * if, swith, for, while, do while 在高级语言的表现
    * 关键是看完本章, 竟然有些不知道要学什么
    * 看得多, 没有记录, 恐慌! 看得少, 不知道该写什么, 烦躁! 怎么维持这个平衡
> 要学什么
    * 对应的底层实现, 要学C语言与汇编的互译
1. 条件码 
- 条件码寄存器, CF(进位标志), ZF(零标志), SF(符号标志), OF(溢出标志)
    * leaq不改变任何条件码, 它用来进行地址计算
    * 算数和逻辑操作指令都会设置条件码
- CMP, TEST
    * CMP S1, S2  =>  S2 - S1, 与SUB指令行为一致
    * TEST S1, S2  => S1 & S2, 与AND指令行为一致, 其中一个操作数是一个掩码, 用来指示哪些位应该被测试
    * CMP, TEST 只设置条件码, 不改变任何其他寄存器

2. 访问条件码: 
- 根据条件码的某种组合, 将一个字节设置0 或 1
- 可以条件跳转到程序的某个其他部分
- 可以有条件地传送数据

- SET (CMP + SET 相当于 if的效果)
    * 就是访问条件码的方式一
    * 指令的后缀表示条件, 而不是大小, >, >=, <, <= 这几种关系, 分为有符号和无符号
    * 有符号就是补码表示, 可以反推出数据类型
    * 同义名
        > 一个机器指令有多个名称
    * 通用指令
        > 等于 sete(setz), 不等于 setne(setnz)
          负数 sets, 非负数 setns
    * 有符号比较
        > 大于 setg(setnle), 大于等于 setge(setnl), 小于 setl(setnge), 小于等于 setle(setng)
    * 无符号比较 above, below
        > 大于 seta(setnbe), 大于等于 setae(setnb), 小于 setb(setnae), 小于等于 setbe(setna)
    * 无符号比较使用的是进标志和零标志组合 

3. 跳转指令
- jmp 
    * 无条件跳转
    * 直接跳转: 跳转目标作为指令编码的一部分  jmp .L1
    * 间接跳转: 跳转目标从寄存器或内存中读出  jmp *(%rax)
- 有条件跳转
    * je, jne 相等/不相等
    * js, jns 负数/非负数
    * jg, jge, jl, jle, 有符号
    * ja, jae, jb, jbe, 无符号
    * 也是根据标志码作为条件判断, 计算指令,CMP, TEST指令, 都会更新标志码
    * 有条件跳转的 相对地址是在下一条指令的基础上加减, 仅仅是在下一条, 里面的逻辑也不合理呀? 但是练习题确是这样
- 跳转指令的编码
    * PC相对的(PC-relative)
    * 绝对地址
    * rep, repz
        + AMD的说法: 当ret指令通过跳转指令到达时, 处理器不能正确预测ret指令的目的, 加入rep能使代码在AMD上运行的更快之外, 不会改变代码的其他(ret)行为
- 用条件传送来实现条件分支
    * 条件传送指令, 更符合现代处理器的性能特性
    * cmov(compare move), 也是根据条件码的值来操作, 只有满足指定条件时, 才会被复制到目的寄存器中
    * 汇编器可以从目标寄存器的名字推断出条件传送指令的操作数长度, 所以对所有的操作数长度, 可以使用同一个的指令名字, 不需要l,w,q来区分
    * cmove/cmovne S,R
    * cmoves/cmovens S,R
    * cmovg/cmova cmovege/cmovae S,R
    * cmovl/cmovle cmovb/cmovbe S,R
    * 条件数据传送提供了一种用条件控制转移来实现条件操作的替代策略. 它们只能用于非常受限的情况, 但是这些情况还是非常常见的, 而且与现代处理器的运行方式更契合
    * 预测分支计算量, 计算量的消耗是否比预测错误的性能处罚大, 这个点正是疑问点, 已经被考虑了, 一般条件里只是简单的一条指令, 适合用于条件传送指令, 由于这种情况非常常见, 所以, 条件传送指令还是有提升性能的特点的
    * 这里也是程序性能优化的地方, 程序员与编译器配合, 尽量不在分支中做过多的计算
    * 条件跳转更通用
- 循环
    * while, do-while, 较高优化等级的编译器(GCC) 加选项 -O1 会将 while 翻译成 do-while, 这说明, do-while的形式更高效?
    * 跳转到中间的翻译方法, guarded-do翻译方法
    * for循环
- switch
    * 跳转表, 每个元素都是一个指向代码位置的指针
    * switch的反汇编有一些难度: 
    * 如何分析跳转表与真实代码的对应关系
    * 跳转表的顺序就是按case值的顺序对应, 根据cmp与ja 判断case值范围, 与default 标签, 跳转表中对应的default跳转即为缺失的case值

#### 过程
0. 传递控制, 伟递数据, 分配和释放内存
1. 运行时栈
- 栈帧

2. 转移控制
- call Q
- M, T, F, L 代表什么含义? 定义函数的首字母
- %rdi(参数1), %rsi(参数2), %rax(返回值), %rsp(栈指针)
- 指令PC如何更新? 就是内存地址
- 各寄存器的值, 是在当条指令执行完毕后才会更新
- 从这里也可以理解, 为何C/C++中要先声明函数定义, 再使用了, 就是要将子函数放在前面, main函数放在最下面, 这样更容易转移控制

3. 数据传送
- x86-64中,大部分的数传传递是通过寄存器实现的
- 寄存器最多可传6个整型, %rdi, %rsi, %rdx, %rcx, %r8, %r9, 大于6个就需要通过栈来传递
- movslq 带符号位扩展, 由4->8, 扩展位置0

4. 栈的上局部存储
- 有些时候, 局部数据必须存放在内存中
    * 寄存器不足够存放本地数据.
    * 对一个局部变量使用地址运算符 &, 因此必须能够为它产生一个地址.
    * 某些局部变量是数组或结构, 因此必须能够通过数组或结构引用被访问到.

5. 寄存器中的局部存储空间
- 调用者保存寄存器, 根据惯例 %rbx, %rbp 和 %r12 ~ %r15, 

6. 递归过程
- 正常的函数调用

#### 数组的分配和访问
1. 基本原则
- 元素大小, 整个数组大小, 元素i的位置

2. 指针运算
- 同上, lea 只是针对地址计算, 不改变寄存器和标志位的值

3. 嵌套的数组
- 连续的数组 T D[R][C];
- 行优先, 列其次, 按公式 &D[i][j] = Xd + L(C*i + j)

4. 定长数组
- 定义需指明大小

5. 变长数组
- 可以使用表达式表示数组, 在分配内存的时候, 根据表达式的值, 分配数组大小
- 原始是不够时, 再moalloc

#### 异数的数据结构
1. 结构(struct)
- 结构嵌套
- 数据对齐
- 总大小为各个字段大小总合
- struct中的数据类型本就是引用, 编译成指令, 在寄存器中存的是地址
- struct 嵌套struct, 内部的struct也会无效, 所有的类型都提到最外层struct, 内部的struct只是在编译器中占用一个符号引用
    此时的内存布局作为一个sturct的对齐方式排列, 嵌套在union中

2. 联合
- 总大小为最大值大小
- struct 在 union中, 按union的内存布局来分配, 在这里可理解, struct 只是相当于一个符号引用, 只在编译器级别占用一个符号, 并不在指令中有内存分配
- 以最大数据类型的大小分配一块内存, 然后可以按照union中的任何类型来访问这块内存, 这个特性猛一看上去, 很棒, 可以将double类型数据按long读出来, 但是应用场景并不多, 而且容易造成误解

3. 数据对齐
- 方便硬件接口的设计, 访问更高效, 但是对不对齐, 都能正常工作
- 对齐的原则: 任何K字节的基本对象的地址必须是K的倍数, 1, 2, 4, 8 
    * 以相邻的数据类型大小较大的作为对齐的标准, 满足大的对齐, 一定满足较小的对齐
- 在编译器层, 也得注意数据对齐, 这是与程序的一个约定

#### 在机器级程序中将控制与数据结合起来
1. 理解指针
- 每个指针都对应一个类型
    指针类型不是机器代码中的一部分, 是C语言提供的一种抽象, 帮助程序员避免寻址错误
- 每个指针都有一个值
    特殊的 NULL(0) 值表示该指针没有指向任何地方
- 指针用 '&' 运算符创建
- '*' 操作符用于间接引用指针
- 数组与指针紧密联系
- 将指针从一种类型强制转换成另一种类型, 只改变它的类型, 而不改变它的值
- 指针也可以指向函数
    函数指针的值是该函数机器代码表示中第一条指令的地址

2. 内存越界引用和缓冲区溢出
- 练习题346(p233)看不太明白, 理解缓冲区溢出攻击大概是个什么意思
- 栈随机化
    * 栈的位置在程序每次运行时都有变化 
    * 程序开始时, 在栈上分配指定字节数量的空间
    * 地址空间布局随机化(ASLR)
    * 空操作雪橇 (nop sled), nop 只会让程序计数器加一, 没有其他效果

- 栈破坏检测
    * 设置canary
    * %fs:40 段地址读取

- 限制可执行代码区域
    * 已经硬件支持, NX(No-Execute)

- 三种最常见的机制, 不需要程序员做任何特殊努力, 带来的性能代价都非常小, 甚至没有

3. 支持变长帧
- %rbp, base pointer, 帧指针
- leave指令, 将帧指针恢复到它之前的值
    等价于 movq %rbp, %rsp
          popq %rbp

#### 浮点代码
 浮点相关, 暂时只作了解
1. 寄存器 
- YMM寄存器: %ymm0 ~ %ymm15
- XMM寄存器: %xmm0 ~ %xmm15

2. 浮点传送和转换操作
- 单精度: vmovss, vmovsd, vmovaps, vmovapd
    Single, Double, Aligned P(?) Single, Aligned P(?) Double
- 双精度: vcvttss2si, vcvttsd2si, vcvttss2siq, vcvttsd2siq
         vcvtsi2ss, vcvtsi2sd, vcvtsi2ssq, vcvtsi2sdq
3. 浮点运算   
- vaddss, vaddsd
- 

4. 在浮点代码中使用位级操作
- vxorps, vandps

5. 比较操作
- ucomiss, ucomisd

## 优化程序性能

    感觉已经有些基础积累, 本章是否可快速通过? 
    程序性能优化从哪几个方面? 
    有何常用手段? 
    性能的评价标准? 
    与语法设计有何关联呢?
    通过语法设计, 性能标准, 找出语言的通用性与特性, 不同领域不同应用.

1. 优化编译器的能力和局限
- 编译器层面的优化, 放在编译指令上, 还是代码实现上, 一般是两者结合
    * 编译指令优化 -Og, -O1, -O2, -O3 默认-O2级别优化
- 编译器的能力有哪些局限?
    * 妨碍优化的因素
        不能确认指针是否指向同一个位置
        函数的多次调用(编译器会假设最糟糕情况, 并保持所有的函数调用不变)
    * GCC只尝试单个文件中定义的函数内联
    * 内联减少程序调用, 但是会增加代码长度, 内联需要注意函数无负作用, 内联的操作相当于define的替换

2. 表示程序的性能
- 程序的性能点体现在哪些地方?
    * 每元素的周期数(Cycles Per Element, CPE)
- 最小二乘拟合
    * y = mx +b, 对E(m,b) 中 m,b分别求导, 导函数设置为0, 求得m,b的算法
    * 最接近于数据代表的 x-y趋势

4. 消除循环的低效率
- 循环哪里会引起低效率
- 不会变的值, 不用在循环里计算多次, 如容器的大小

5. 减少过程调用
- 过程调用为何要减少, 哪些地方增加了开销?
    * 存栈, 分配内存, 恢复栈
    * 妨碍大多数形式的程序优化

6. 消除不必要的内存引用
- 内存引用会引起效率? 寻址上吗?
    * 从内存中读写要比访问寄存器慢, 所以, 临时局部变量很有必要
    * 访问即寻址

7. 理解现代处理器
- 现在处理器需要学习的点有哪些?
    * 指令级并行
    * 吞吐量界限, 是程序性能的终极界限
    * 超标量, 乱序的(out-of-order),能更好地达到更高的指令级并行度
    * 高速缓存
    * 分支预测技术

- concept
    * 投机执行(speculative execution)
    * 分支预测(branch prediction)
    * 指令译码逻辑
    * 寄存器文件(寄存器本身?)
    * 退役单元(retirement unit)
    * 寄存器重命名(register renaming)
    * 延迟(lantency), 表示完成运算所需要的总时间
    * 发射时间(issue time), 表示两个连续的同类型运算之阐需要的最小时钟周期数
    * 最大吞吐量, 定义为发射时间的倒数
    * 容量(capacity), 表示能够执行该运算的功能单元的数量.

8. 循环展开
- 循环展开, 并不是由C循环翻译成汇编的方式
- a. 减少不直接有助于程序结果的操作的数量, 如循环索引计算和条件分支
- b. 减少整个计算中关键路径上的操作数量
- GCC 优化等级3或更高等级, 就会执行循环展开

9. 提高并行性
- 多线程编程会提高性能, 多线程编程也会增加开销, 平衡点在哪里?
- a. 多个累积变量
- b. 

10. 优化合并代码的结果小结
- 合并代码指得是什么? 为何这里有个小结
    * 重新结合变换， 如将循环二次遍历合为一次, 能够减少关键路径上操作的数量
    * 用向量指令达到更高的并行度
    * 多项优化技术, 非常程式化的方式

11. 一些限制因素
- 限制因素有哪些? 硬件层面, 软件层面, 客观人力?
- 寄存器溢出
    * x86-64 有足够多的寄存器， 大多数循环在出现寄存器溢出之前就将达到吞吐量限制
- 分支预测和预测错误惩罚

12. 理解内存性能
- 内存性能指标是什么?
    * 高速缓存区
    * 加载的性能, 依赖于流水线的能力， 也依赖于加载单元的延迟
    * 存储的性能

- 有何优化手段
    * 

13. 应用: 性能提高技术
- 实际应用
- 高级设计. 为遇到的问题选择适当的数据结构和算法
- 基本编码原则.
    * 避免优化限制的因素， 依靠编译器才能产生高效的代码
    * 消除不必要的内存引用. 引入临时变量来保存中间结果。 
- 低级优化. 结构化代码以利用硬件功能 
    * 展开循环, 降低开销
    * 通过使用多个累加变量和重新结合等技术， 找到方法提高指令并行
    * 用功能性的风格重写条件操作（三目运算符？：）， 使得编译器采用条件传送数据

14. 确认和消除性能瓶颈
- 实战? 
- 代码剖析程序( code profiler)
    * gprof 工具
- Amdahl定律

15. 小结
- 性能优化方面:
    1. 主要目的就是减少所有指令执行的时钟周期
    2. 一个是 寄存器=堆栈 >= 内存 的访问速率
    3. 循环里减少计算量, 减少函数调用
    4. 函数会妨碍编译器优化, 编译器对于函数的优化, 都是以最糟糕的情况来假设, 这样稳妥保证不出错

## 存储器层次结构
1. 简单了解一下， 以便于有个概念
- 高速缓存器的工作原理
- 编写代码， 怎么控制高速缓存器呢？
- 如何应用在实战上， 买电脑时， 有没有参考呢？

2. 存储技术
- SRAM, DRAM, ROM
- 高速缓冲区对程序的性能影响最大
- 双稳态电路特性, 但得有电
- 内存系统必须周期性地通过读出，然后重写来刷新每一位内存
- 纠错码， 多编码几位
- 内存控制器
- 磁盘原理, 转速，盘面， 磁道， 扇区， 备用扇区
- 总线， 是一个简单的抽象， 可以具体描述但又不必和某个系统的细节联系过于紧密
- 内存映射
- 磁盘读取过程: 
    CPU 发送指令到磁盘控制器 -> 磁盘控制器将扇区读到主存(DMA, 直接内存访问) -> 硬盘控制器以中断通知cpu 
- SSD
    * 数据是以页为单位读写的
    * 只有在一页所属的块整个被擦除后，才能写这一页
    * 一旦一个块被擦除后， 块中的每一个页都可以不需要再进行擦除就写一次
    * 在大约100 000 次重复(擦除）写之后, 块就会磨损坏

3. 局部性
- 局部性： 倾向于引用邻近于其他最近引用过的数据项的数据项， 或者最近引用过的数据项本身
- 时间局部性， 空间局部性
    * 在不远的将来， 会再被多次访问数据
    * 在不远的将来， 会再被卧多次访问该数据附近的一个内存位置
        二维数组遍历， 按行列遍历， 具有空间局部性
- 重复引用相同变量的程序具有良好的时间局部性
- 对于具有步长为 k 的引用模式的程序， 步长越小， 空间局部性越好
- 对于取指令来说（不改变数据),循环具有良好的时间和空间局部性

4. 存储器层次结构
- 寄存器 > 高速缓冲区 > 内存 > 本地磁盘 > 远程分布式磁阵列
- 高速缓存， 缓存命中， 缓存不命中
    * 在第k层不命中的时候， 向第k+1取数据， 复制到k层， 然后下一次就可以继续从k层命中
    * 替换/驱逐, 牺牲块, 替换策略
    * 强制不命中/冷命中， 放置策略, 冲突不命中, 容量集， 容量不命中

5. 高速缓存存储器
- 讲述实现原理， 暂时略过
- 抖动: 调整缓存反复地加载和驱逐相同的高速缓存块的组
    * 抖动造成冲突不命中

6. 编写高速缓存友好的代码
- 让最常见的情况运行得快
- 尽量减小每个循环内部的缓存不命中数量
    * 对局部变量反复引用是好的
    * 步长为1的引用模式是好的
- 存储器山
    * 以不同的size(时间局部性) 和 stride(空间局部性) 的值组件的函数(测量和计算读吞吐量)图

7. 小结
- 

## 链接
1. 编译时， 加载时， 运行时， 链接器， 分享编译
- 有助于构造大型程序
- 避免一些危险的编程错误
- 语言的作用域规则是如何实现的
- 其他重要的系统概念
- 利用共享库

2. 编译器驱动程序
- 依次执行 cpp（C预处理器), ccl(C编译器), as(汇编器), ld(链接器), 创建一个可执行目标文件
- shell 调用操作系统中的加载器, 将可执行文件中的代码和数据复制到内存取，然后控制转移到这个程序的开头

3. 静态链接
- 符号解析 
    symbol resolution
- 重定位
    relocation

4. 目标文件
- 可重定位目标文件
- 可执行目标文件
- 共享目标文件
- 目标文件，目标模块，等同于一个概念
    a.out, 
    portable executable, 
    match-o, 
    executable and linkable format

5. 可重定位目标文件
- elf 文件格式
    .text
    .rodata
    .data
    .bss
    .symtab
    .rel .text
    .rel .data
    .debug
    .line
    .strtab

6. 符号和符号表
- 由模块m定义并能被其他模块引用的全局符号
    非静态C函数和全局变量
- 由其他模块定义并被m模块引用的全局符号
    非静态C函数和全局变量
- 只被模块m定义和引用的局部符号
    带static 的C函数和全局变量

7. 符号解析
- 强定义, 弱定义
    全局且初始化的变量和函数 为强， 反之为弱
- linux处理规则：
    * 不允许有多个同名的强符号
    * 如果有一个强符号和多个弱符号同名， 选择弱符号
    * 如果有多个弱符号同名， 任选一个
- gcc -fno-common 告诉编译器，遇到多重定义的全局符号时，触发一个错误
- -Werror 会将所有的警告都变为错误
- 与静态库链接
    * 静态库是为了解决代码利用问题，从编译器实现复杂度与磁盘空间浪费度综合考虑的产物
    * 静态库是存档文件
    * 链接器只复制用到的代码到可执行程序
    * 从左到右解析, 所以静态库如果有依赖关系， 顺序不可以乱
        >a. 重复库
        >b. 声明引用一定要出现在定义之前

8. 重定位
- 重定位节和符号定义
    * 将所有相同类型的节合并为同一类型的新的聚合节
- 重定位节中的符号引用
    * 指向正确的运行时地址
    * 重定位条目放在 .rel .text 节中
    * 相对地址， 绝对地址
- 链接器每一步做得事都足够简单， 但是组合到一起， 效果就很神奇

9. 可执行目标文件
- 按节的顺序排列的二进制数据格式
- 将程序复制到内存并运行的过程叫做加载
- 程序的开始地址和栈的开始地址一般都是固定的，固定不用怕栈溢出吗？
- 所谓内核就是操作系统驻留在内存的部分，不会被释放
- 内存总是一种稀缺资源， 不论系统内存有多大

10. 动态链接共享库
- 动态链接器
- 允许多个正在运行的进程共享内存中相同的库代码， 因而节约宝贵的内存资源

11. 从应用程序中加载和链接共享库
- 是一项很牛逼的技术， 典型例子是web服务器, 将fork的开销变成函数的动态调用开销
- jni， 是动态链接和加载的典型例子

12. 位置无关代码
- 多个进程是如何共享程序的一个副本的呢？
- PIC, Position-Independent Code
- -fpic 共享库的编译必须总是使用该选项, 那为何不做成默认的呢？
- 数据段与代码端的距离总是保持不变, 相对寻址技术
- GOT, Global Offset Table
- 延时绑定，lazy binding
    将过程地址的绑定推迟到第一次调用该过程时
- 过程链接表, PLT, Procedure Linkage Table

13. 库打桩机制
- aop 的思想
- 给定一个需要打桩的目标函数， 创建一个包装函数， 它的原型与目标函数完全一样。 使用某种特殊的打桩机制， 就可以欺骗系统调用包装函数而不是目标函数了
- 编译时 
    -DCOMPILETIME, -I
- 链接时 
    -DLINKTIME, --wrap f
- 加载运行时
    LD_PRELOAD

14. 处理目标文件工具
- ar: 创建静态库， 插入，删除， 列出和提取成员
- string: 列出一个目标文件中所有可打印的字符串
- strip: 从目标文件中删除符号表信息
- nm: 列表一个目标文件的符号表中的定义的符号
- size: 列出目标文件夹中节的名字和大小
- readelf: 显示一个目标文件夹的完整结构， 包含size和nm功能
- objdump: 所有二进制工具之母。 能够显示一个目标文件中的所有信息. 是大作用是反汇编.text节中的二进制指令。
- ldd: 列出一个可执行文件在运行是所需要的共享库

15. 小结
- 如何编译出.o 文件？

## 异常控制流
1. 

## 虚拟内存
> 硬件异常， 硬件地址翻译，主存，磁盘文件和内核软件的完美交互, 为每个进程提供一个大的， 一致的和私有的地址空间
1. 物理和虚拟地址
- 物理寻址, CPU访问内存的最自然的方式就是使用物理地址
- 虚拟寻址, 虚拟地址(VA, Virtual Address), 内存管理单元(MMU, Memory Management Unit)
    利用存放在主存中的查询表来动态翻译虚拟地址， 该表的内容由操作系统管理
- 计算机中有太多这样的中间单元来作为代理角色，统一接口，操作方式 

2. 地址空间
- 一个地址空间大小是由表示最大地址所需要的位数来描述的, 2^n
- 物理内存大小不要求是2的幂

3. 虚拟内存作为缓存的工具
- 虚拟页， 物理页(PP, Physical Page), 有固定大小， 物理=虚拟
    物理页数和虚拟页数相等吗? 不一定， 物理地址可以是主存， 也可以是磁盘， 虚拟的只需要记录物理的起始位置， 就可以使用, 那样的话， 物理哪些页使用完了该怎么记录呢？
    虚拟>=物理（仅限于主存，不算磁盘的)
- PTE(Page Table Entry), 由一个有效位和一个n位地址字段组成的
    有效位表明了该虚拟页当前是否被缓存在DRAM中 
- 页表就是一个页表条目数组， 大小为最大寻址数/每页大小(2^n / 2^p = 2^(n-p)), 最大寻址是按地址位数(总线位数)， 物理理论上没有限制， 因为还有磁盘, 但是虚拟内存>=物理主存, 最主要操作还是在主存上
    早期的虚拟地址小于主存， 但是仍然有意义， 简化了内存管理
- DRAM缓存(主存)是全相联的， 是什么意思, 物理页可以和任意虚拟页相联
- 页命中, 缺页（不命中), 按需页面调度(demand paging)
- 抖动， 工作集的大小超期出了物理内存的大小, 页面将不断地换进换出

4. 虚拟内存为内在管理的工具
- 操作系统为每一个进程提供了一个独立的页表, 因而也就是一个独立的虚拟地址空间
    多个虚拟页面可以映射到同一个共享物理页面上, 每个进程的内存中间有一段对齐的空白
- VM简化了链接和加载， 代码和数据共享， 以及应用程序中的内在分配
- 简化链接
    独立的地址空间允许每个进程的内存映像使用相同的格式, 而不管代码和数据实际存放在物理内存何处.
- 简化加载
    虚拟内存系统会按照需要自动调入数据页
    内存映射， 将一组连续的虚拟页映射到任意一个文件夹中任意位置的表示法
- 简化共享
    每个进程不共享的数据, 被操作系统将虚拟页映射到不连续的物理页面, 共享的代码和数据(如标准库中的程序)通过将不同进程中适当的虚拟页面映射到相同的物理页面, 从而安排多个进程共享这部分代码的一个副本, binder机制就是怎么识别这样的共享区域？
- 简化内存分配
    操作系统可以保证虚拟内存连续， 物理内存没必要连续， 而虚拟内存是对用户可见的
- 小结： 虚拟内存对用户可见， 用户可以是链接器， 也可以是程序员编写的应用， 而操作系统主要来维护虚拟表与物理表的映身操作， 而这种操作也是通用的，功能单一的， 可是真正要注意的东西挺多， 已使用的物理内存映射查询， 共用的物理内存， 所以，这套系统是复杂精密的， 功能单一是从宏观操作上来说， 抽取所有内存管理的通用部分

5. 虚拟内存作为内存保护工具
- 带有许可位的PTE
- 违反了许可条件， CPU触发一个保护故障， 将控制传递给内核中的异常处理程序， 报告为"段错误(segmentation fault)"

6. 地址翻译
- 基本参数
    * N = 2^n, N 为最大虚拟内存容量， n 为地址位数
    * M = 2^m, M 为最大物理内存容量， m 为地址位数
    * P = 2^p, P 为页的大小(字节),  n-p 为虚拟页号
- 虚拟地址(VA)
    * VPO, 虚拟页面的偏移量
    * VPN, 虚拟页号
    * TLBI, TLB(翻译后备缓冲器, translate lookaside buffer)索引
    * TLBT, TLB 标记
- 物理地址(PA)
    * PPO, 物理页面偏移量
    * PPN, 物理页号
    * CO, 缓冲块内的字节偏移量
    * CI, 调整缓存索引
    * CT, 调整缓存标记
- 结合高速缓存和虚拟内存
    * 大数多系统是选择物理寻址
    * 地址翻译发生成高速缓存查找之前
- 多级页表

7. Intel Core i&/Linux内存系统
- 

8. 内存映射
- 

9. 动态内存分配
- 

10.垃圾收集 
- 

11. C程序中常见的内存有关错误
- 

## 系统级I/O
## 网络编程
## 并发编程

