
## 深入理解计算机操作系统

    Computer Systems - A Programmer's Perspective 
    是时候走一遍了, 有些细节先不深究, 如 float数据, 补码之类
    按顺序读, 太难的, 也先过... 如 处理器体系结构
    主要有个整体的概念, 然后捡感兴趣的章节先读
    优化程序性能, 虚拟内存, 异常控制流, 系统级I/O, 网络编程, 并发编程

## 1. 计算机系统漫游
####  位+上下文
1. 文本文件 和 二进制文件 
2. 上下文, 现在看来没啥疑问, 当初可是怎么都想不明白
3. 看不懂的书, 肯定是积累不够

####  程序
1. 翻译成各种形式的字节码
    > 预处理器 -> 编译器 -> 汇编器 -> 链接器
2. GNU环境 
    * EMACS编辑器, GCC编译器, GDB调试器, 汇编器, 链接器, 处理二进制文件的工具及其他一些部件
    * free
####  编译系统
1. 编译器是如何将代码转换成不同平台的机器语言
2. 优化程序性能
3. 理解链接时出现的错误
4. 避免安全漏洞

####  处理器解释指令 
1. shell 解释可执行程序
2. 系统的硬件组成
- 总线
    * 电子管道
- I/O设备
    * 每个I/O设备都通过一个控制器和适配器与I/O总线相连
    * 控制器和适配器的区别主要在于它们的封装方式
- 主存
    * DRAM (dynamic random access memory)
    * 即内存, 临时存储

- 处理器
    * 核心是一个大小为一个字的存储设备, 程序计数器(PC), 指向主存中的机器指令
    * 指令集架构, 微体系结构
    * 寄存器文件是啥, 存放几百字节, CPU 和 ALU各16个? 跟这还不一样, 专门设计的SRAM, 寄存器堆, 
####  高速缓存
1. 高速缓存 SRAM(static random access memory)
- 高速缓存的局部性原理

####  储存设备
1. 存储器层次结构
- 寄存器 > L1高速缓存 > L2 > L3 > 主存(DRAM, 内存) > 本地二级存储 > 远程二级存储

####  操作系统管理硬件 
1. 抽象概念
- 进程 
    * 对正在运行的程序的一种抽象
    * 上下文切换 
    * 线程
- 虚拟内存 
    * 为每个进程提供一个假象, 即独占地使用主存
    * 每个进程看到的内存都是一致的, 称为虚拟地址空间

- 文件
    * 字节序列, 仅此而已
    * 向应用程序提供了一个统一的视图, 来看待系统中可能含有的所有各式各样的I/O设备

2. 内核
- 内核管理管理进程上下文的切换
- 内核是常驻主存的部分
- 内核不是一个独立的进程, 是系统管理全部进程所用代码和数据结构的集合

####  网络通信
1. 网络也是一种I/O设备
2. 通过网络适配器完成机器间的数据复制 

####  重要主题
1. Amdahl 定律
- 要想显著加速整个系统, 必须提升全系统中相当大的部分的速度 
- 描述了改善任何过程的一般原则
- 整体与部分的关系

2.  并发和并行
- 并发 (concurrency) 是一个通用的概念, 指一个同时具有多个活动的系统
- 并行(parallelism) 指的是用并发来使一个系统运行得更快
- 线程级并发
    * 在一个进程中执行多个控制流
    * 多核处理器
        * 每个核有各自的L1和L2高速缓存器, 共享更高层次的高速缓存
        * 从两个方面提高系统性能
        > 1. 减少了在执行多个任务时模拟并发的需要, (这里的模拟并发, 是分配时间片, 上下文切换的消耗么?)
        2. 可以使应用程序运行得更快, 前提是使用多线程编写
    * 超线程
        * 同时多线程(simultaneous multi-threading)
        * 一个CPU执行多个控制流的技术
- 指令级并行
    * 在较低层次的抽象上, 现代处理器同时执行多条指令
    * 超标量(super-scalar)处理器: 比一个周期一条指令更快的执行效率
    * 单指令, 多数据并行
3. 计算机系统中抽象的重要性
- 提供不同层次的抽象表示, 来隐藏实际实现的复杂性
- |- 虚拟机
    |- 操作系统
    |- 进程
        |- 指令集架构
            |- 处理器
        |- 虚拟内存
            |- 主存
            |- 文件 I/O设备

####  小结

## 2. 信息的表示与处理
#### 信息存储
1. 无符号数, 有符号数, 浮点数
- 溢出
- 补码
- 浮点运算是不可结合的 

2. 信息存储
- 虚拟内存上, 非常大的字节数
- 编译器和运行时系统将存储空间划分为更可管理的单元
- 程序对象: 程序数据, 指令, 控制信息 
- 可移植性的一个方面: 使程序对不同数据类型的确切大小不敏感

3. 寻址和字节顺序
- 大小端
- 最低有效字节, 从左向右开始, 指的就是数字的高低位

4. 布尔代数
- 与, 或, 非, 异或
- 信息论领域
- 布尔环, 长度为w的位向量上的 ^, & 和 ~ 运算时, 会得到一种不同的数学形式
    a & a = a;  a^a = 0;  0^b = b;
- 位向量运算, 分别将向量的每一位进行 与或非运算
- 位向量与集合的表示
    从右向左, 位向量为1的位置, 构成集合
- 掩码 
- 逻辑运算, 移位运算
    * 逻辑右移, 填充0
    * 算术右移, 按高位值填充
    * 左移都是填充0 
    * 约定有符号数都使用算术右移, 无符号数必须是逻辑右移
    * java中 >> 表示算术移位, >>> 表示逻辑移位

#### 整数表示
1. 无符号数编码的唯一性
- 双射
2. 补码编码
- 有符号数 使用 补码形式
- 补码编码的唯一性
    * 跟无符号数的编码一致, 但是高位为符号位
    * 正数的补码跟原码一致, 负数的补码还原, 符号位不变, 其余位取反加1, (这个还原也只是为了方便人工计算值, 机器计算还是直接用补码计算)
    * 这个性质就是在计算过程中发现的, 算不上推理(我比较倾向于推理的结果, 就是得到证明的结果, 而不是靠经验得出来的结果, 这个观念得改一改)
- 补码和反码

3. 有符号数和无符号数之间的转换
- C语言中不管数值信息, 保留位模式信息, 按强转的类型解释
- 补码转无符号数
- 无符号数转补码, 两个操作反过来
- 有符号数与无符号数比较, 默认先将有符号数转换成无符号数, 这样就会出现一些奇怪的现象
    负数比0大
- INT_MIN 和 INT_MAX
    * #define INT_MIN  (-INT_MAX - 1)

4. 扩展一个数字的位表示
- 无符号数的零扩展
- 补码数的符号扩展
- 截断无符号数 与 截断补码数值

5. 注意事项
- 比较, 数传运算, 避免使用无符号数
- 无符号数可做位的集合, 没有任何数字意义时, 比较好用, 用作mask 

#### 整数运算
1. 正溢出, 负溢出
2. 加, 乘
#### 浮点数
#### 小结
1. 数据表示后续有需求再研究

## 3. 程序的机器级表示
#### 历史观点
1. IA32, X86-64(X86), i386, i486, 
2. K(10^3), M(10^6), G(10^9)
#### 程序编码
1. 机器级代码 
- ISA(Instruction Set Architecture), 指令集架构
- 程序计数器(PC) %rip 给出要执行的下一条指令在内存中的地址
- C语言中的数据类型, 在机器代码中用一组连续的字节来表示, 不区分有无符号, 指针类型, 指针和整数
- x86-64的指令长度从1到15个字节不等, 常用的字节少, 不常用的字节多
- 反汇编器, 直接根据机器指令码序列来确定汇编代码, 与GCC编译出来的有差译, 但是不影响阅读
- ATT(AT&T) 与 Intel 汇编代码格式
    默认使用 ATT, Intel的编码代码比对学习, 多位操作数, 顺序不一致
- 

#### 数据格式
1.  汇编代码后缀
- 字节:b, 字:w, 双字:l, 四字:q, 单精度:s, 双精度:l
    双字和双精度都是l, 不会产生歧义, 因为机器指令和寄存器不同

#### 访问信息
1. 通用目的寄存器
- 16位(%ax-%bp), 32位(%eax-%ebp), 64位(%rax-%rbp, %r8-%r15)
2. 操作数指示符
- 立即数 ($), 寄存器(R[ra]), 内存引用(Mb[Addr])
- 寻址模式: 立即数(Imm), 寄存器(rb), 绝对, 间接, 基址+偏移量, 变址(Imm + R[rb] + R[ri]), 比例变址
- 数据传送指令: mov, 内存/寄存器 -> 寄存器, 目的大于源
    * 零扩展数据传送指令 zbw, zbl, zwl, zbq, zwq
    * 符号扩展数据传送指令 sbw, sbl, swl, sbq, slq, cltq
- 压入和弹出栈数据
    pushq
    popq
#### 算数和逻辑操作
0. 操作数
- 立即数, 寄存器, 内存地址
- 立即数不可作为目的操作数
- 内存地址作为目的操作数时, 处理器必须从内存读出值, 执行操作, 再将结果写回内存

1. 加载有效地址
- leaq S,D 
    D <- &S
    目的操作数必须是一个寄存器
    movq 的变形, 但是并没有引用内存, 而是直接将有效地址写入目的操作数(相当于指针级别的操作咯)

2. 一元操作
- INC D
- DEC D
- NEG D
- NOT D

3. 二元操作
- ADD S, D
    D <- D+S

- SUB, IMUL, XOR, OR, AND
    同上
    imul 两个操作数时, 64位乘积, 一个操作数时, 128位乘积, %rdx 高64位, %rax 低64位
    
- 第二个操作数同时作为目的操作数

4. 移位
- SAL k,D 
    D <- D << k
- SHL, 等同于 SAL
- SAR k,D
    算术右移
- SHR k,d 
    逻辑右移
- 目的操作数为 立即数或寄存器
    寄存器只能使用 %cl
    salb 移7位, salw 移15位, sall 移31位, salq 移63位

#### 控制
> 已知什么
    * if, swith, for, while, do while 在高级语言的表现
    * 关键是看完本章, 竟然有些不知道要学什么
    * 看得多, 没有记录, 恐慌! 看得少, 不知道该写什么, 烦躁! 怎么维持这个平衡
> 要学什么
    * 对应的底层实现, 要学C语言与汇编的互译
1. 条件码 
- 条件码寄存器, CF(进位标志), ZF(零标志), SF(符号标志), OF(溢出标志)
    * leaq不改变任何条件码, 它用来进行地址计算
    * 算数和逻辑操作指令都会设置条件码
- CMP, TEST
    * CMP S1, S2  =>  S2 - S1, 与SUB指令行为一致
    * TEST S1, S2  => S1 & S2, 与AND指令行为一致, 其中一个操作数是一个掩码, 用来指示哪些位应该被测试
    * CMP, TEST 只设置条件码, 不改变任何其他寄存器

2. 访问条件码: 
- 根据条件码的某种组合, 将一个字节设置0 或 1
- 可以条件跳转到程序的某个其他部分
- 可以有条件地传送数据

- SET (CMP + SET 相当于 if的效果)
    * 就是访问条件码的方式一
    * 指令的后缀表示条件, 而不是大小, >, >=, <, <= 这几种关系, 分为有符号和无符号
    * 有符号就是补码表示, 可以反推出数据类型
    * 同义名
        > 一个机器指令有多个名称
    * 通用指令
        > 等于 sete(setz), 不等于 setne(setnz)
          负数 sets, 非负数 setns
    * 有符号比较
        > 大于 setg(setnle), 大于等于 setge(setnl), 小于 setl(setnge), 小于等于 setle(setng)
    * 无符号比较 above, below
        > 大于 seta(setnbe), 大于等于 setae(setnb), 小于 setb(setnae), 小于等于 setbe(setna)
    * 无符号比较使用的是进标志和零标志组合 

3. 跳转指令
- jmp 
    * 无条件跳转
    * 直接跳转: 跳转目标作为指令编码的一部分  jmp .L1
    * 间接跳转: 跳转目标从寄存器或内存中读出  jmp *(%rax)
- 有条件跳转
    * je, jne 相等/不相等
    * js, jns 负数/非负数
    * jg, jge, jl, jle, 有符号
    * ja, jae, jb, jbe, 无符号
    * 也是根据标志码作为条件判断, 计算指令,CMP, TEST指令, 都会更新标志码
    * 有条件跳转的 相对地址是在下一条指令的基础上加减, 仅仅是在下一条, 里面的逻辑也不合理呀? 但是练习题确是这样
- 跳转指令的编码
    * PC相对的(PC-relative)
    * 绝对地址
    * rep, repz
        + AMD的说法: 当ret指令通过跳转指令到达时, 处理器不能正确预测ret指令的目的, 加入rep能使代码在AMD上运行的更快之外, 不会改变代码的其他(ret)行为
- 用条件传送来实现条件分支
    * 条件传送指令, 更符合现代处理器的性能特性
    * cmov(compare move), 也是根据条件码的值来操作, 只有满足指定条件时, 才会被复制到目的寄存器中
    * 汇编器可以从目标寄存器的名字推断出条件传送指令的操作数长度, 所以对所有的操作数长度, 可以使用同一个的指令名字, 不需要l,w,q来区分
    * cmove/cmovne S,R
    * cmoves/cmovens S,R
    * cmovg/cmova cmovege/cmovae S,R
    * cmovl/cmovle cmovb/cmovbe S,R
    * 条件数据传送提供了一种用条件控制转移来实现条件操作的替代策略. 它们只能用于非常受限的情况, 但是这些情况还是非常常见的, 而且与现代处理器的运行方式更契合
    * 预测分支计算量, 计算量的消耗是否比预测错误的性能处罚大, 这个点正是疑问点, 已经被考虑了, 一般条件里只是简单的一条指令, 适合用于条件传送指令, 由于这种情况非常常见, 所以, 条件传送指令还是有提升性能的特点的
    * 这里也是程序性能优化的地方, 程序员与编译器配合, 尽量不在分支中做过多的计算
    * 条件跳转更通用
- 循环
    * while, do-while, 较高优化等级的编译器(GCC) 加选项 -O1 会将 while 翻译成 do-while, 这说明, do-while的形式更高效?
    * 跳转到中间的翻译方法, guarded-do翻译方法
    * for循环
- switch
    * 跳转表, 每个元素都是一个指向代码位置的指针
    * switch的反汇编有一些难度: 
    * 如何分析跳转表与真实代码的对应关系
    * 跳转表的顺序就是按case值的顺序对应, 根据cmp与ja 判断case值范围, 与default 标签, 跳转表中对应的default跳转即为缺失的case值

#### 过程
0. 传递控制, 伟递数据, 分配和释放内存
1. 运行时栈
- 栈帧

2. 转移控制
- call Q
- M, T, F, L 代表什么含义? 定义函数的首字母
- %rdi(参数1), %rsi(参数2), %rax(返回值), %rsp(栈指针)
- 指令PC如何更新? 就是内存地址
- 各寄存器的值, 是在当条指令执行完毕后才会更新
- 从这里也可以理解, 为何C/C++中要先声明函数定义, 再使用了, 就是要将子函数放在前面, main函数放在最下面, 这样更容易转移控制

3. 数据传送
- x86-64中,大部分的数传传递是通过寄存器实现的
- 寄存器最多可传6个整型, %rdi, %rsi, %rdx, %rcx, %r8, %r9, 大于6个就需要通过栈来传递
- movslq 带符号位扩展, 由4->8, 扩展位置0

4. 栈的上局部存储
- 有些时候, 局部数据必须存放在内存中
    * 寄存器不足够存放本地数据.
    * 对一个局部变量使用地址运算符 &, 因此必须能够为它产生一个地址.
    * 某些局部变量是数组或结构, 因此必须能够通过数组或结构引用被访问到.

5. 寄存器中的局部存储空间
- 调用者保存寄存器, 根据惯例 %rbx, %rbp 和 %r12 ~ %r15, 

6. 递归过程
- 正常的函数调用

#### 数组的分配和访问
1. 基本原则
- 元素大小, 整个数组大小, 元素i的位置

2. 指针运算
- 同上, lea 只是针对地址计算, 不改变寄存器和标志位的值

3. 嵌套的数组
- 连续的数组 T D[R][C];
- 行优先, 列其次, 按公式 &D[i][j] = Xd + L(C*i + j)

4. 定长数组
- 定义需指明大小

5. 变长数组
- 可以使用表达式表示数组, 在分配内存的时候, 根据表达式的值, 分配数组大小
- 原始是不够时, 再moalloc

#### 异数的数据结构
1. 结构(struct)
- 结构嵌套
- 数据对齐
- 总大小为各个字段大小总合
- struct中的数据类型本就是引用, 编译成指令, 在寄存器中存的是地址
- struct 嵌套struct, 内部的struct也会无效, 所有的类型都提到最外层struct, 内部的struct只是在编译器中占用一个符号引用
    此时的内存布局作为一个sturct的对齐方式排列, 嵌套在union中

2. 联合
- 总大小为最大值大小
- struct 在 union中, 按union的内存布局来分配, 在这里可理解, struct 只是相当于一个符号引用, 只在编译器级别占用一个符号, 并不在指令中有内存分配
- 以最大数据类型的大小分配一块内存, 然后可以按照union中的任何类型来访问这块内存, 这个特性猛一看上去, 很棒, 可以将double类型数据按long读出来, 但是应用场景并不多, 而且容易造成误解

3. 数据对齐
- 方便硬件接口的设计, 访问更高效, 但是对不对齐, 都能正常工作
- 对齐的原则: 任何K字节的基本对象的地址必须是K的倍数, 1, 2, 4, 8 
    * 以相邻的数据类型大小较大的作为对齐的标准, 满足大的对齐, 一定满足较小的对齐
- 在编译器层, 也得注意数据对齐, 这是与程序的一个约定

#### 在机器级程序中将控制与数据结合起来
1. 理解指针
- 每个指针都对应一个类型
    指针类型不是机器代码中的一部分, 是C语言提供的一种抽象, 帮助程序员避免寻址错误
- 每个指针都有一个值
    特殊的 NULL(0) 值表示该指针没有指向任何地方
- 指针用 '&' 运算符创建
- '*' 操作符用于间接引用指针
- 数组与指针紧密联系
- 将指针从一种类型强制转换成另一种类型, 只改变它的类型, 而不改变它的值
- 指针也可以指向函数
    函数指针的值是该函数机器代码表示中第一条指令的地址

2. 内存越界引用和缓冲区溢出
- 练习题346(p233)看不太明白, 理解缓冲区溢出攻击大概是个什么意思
- 栈随机化
    * 栈的位置在程序每次运行时都有变化 
    * 程序开始时, 在栈上分配指定字节数量的空间
    * 地址空间布局随机化(ASLR)
    * 空操作雪橇 (nop sled), nop 只会让程序计数器加一, 没有其他效果

- 栈破坏检测
    * 设置canary
    * %fs:40 段地址读取

- 限制可执行代码区域
    * 已经硬件支持, NX(No-Execute)

- 三种最常见的机制, 不需要程序员做任何特殊努力, 带来的性能代价都非常小, 甚至没有

3. 支持变长帧
- %rbp, base pointer, 帧指针
- leave指令, 将帧指针恢复到它之前的值
    等价于 movq %rbp, %rsp
          popq %rbp

#### 浮点代码
 浮点相关, 暂时只作了解
1. 寄存器 
- YMM寄存器: %ymm0 ~ %ymm15
- XMM寄存器: %xmm0 ~ %xmm15

2. 浮点传送和转换操作
- 单精度: vmovss, vmovsd, vmovaps, vmovapd
    Single, Double, Aligned P(?) Single, Aligned P(?) Double
- 双精度: vcvttss2si, vcvttsd2si, vcvttss2siq, vcvttsd2siq
         vcvtsi2ss, vcvtsi2sd, vcvtsi2ssq, vcvtsi2sdq
3. 浮点运算   
- vaddss, vaddsd
- 

4. 在浮点代码中使用位级操作
- vxorps, vandps

5. 比较操作
- ucomiss, ucomisd

## 优化程序性能

    感觉已经有些基础积累, 本章是否可快速通过? 
    程序性能优化从哪几个方面? 
    有何常用手段? 
    性能的评价标准? 
    与语法设计有何关联呢?
    通过语法设计, 性能标准, 找出语言的通用性与特性, 不同领域不同应用.

1. 优化编译器的能力和局限
- 编译器层面的优化, 放在编译指令上, 还是代码实现上, 一般是两者结合
    * 编译指令优化 -Og, -O1, -O2, -O3 默认-O2级别优化
- 编译器的能力有哪些局限?
    * 妨碍优化的因素
        不能确认指针是否指向同一个位置
        函数的多次调用(编译器会假设最糟糕情况, 并保持所有的函数调用不变)
    * GCC只尝试单个文件中定义的函数内联
    * 内联减少程序调用, 但是会增加代码长度, 内联需要注意函数无负作用, 内联的操作相当于define的替换

2. 表示程序的性能
- 程序的性能点体现在哪些地方?
    * 每元素的周期数(Cycles Per Element, CPE)
- 最小二乘拟合
    * y = mx +b, 对E(m,b) 中 m,b分别求导, 导函数设置为0, 求得m,b的算法
    * 最接近于数据代表的 x-y趋势

4. 消除循环的低效率
- 循环哪里会引起低效率
- 不会变的值, 不用在循环里计算多次, 如容器的大小

5. 减少过程调用
- 过程调用为何要减少, 哪些地方增加了开销?
    * 存栈, 分配内存, 恢复栈
    * 妨碍大多数形式的程序优化

6. 消除不必要的内存引用
- 内存引用会引起效率? 寻址上吗?
    * 从内存中读写要比访问寄存器慢, 所以, 临时局部变量很有必要
    * 访问即寻址

7. 理解现代处理器
- 现在处理器需要学习的点有哪些?
    * 指令级并行
    * 吞吐量界限, 是程序性能的终极界限
    * 超标量, 乱序的(out-of-order),能更好地达到更高的指令级并行度
    * 高速缓存
    * 分支预测技术

- concept
    * 投机执行(speculative execution)
    * 分支预测(branch prediction)
    * 指令译码逻辑
    * 寄存器文件(寄存器本身?)
    * 退役单元(retirement unit)
    * 寄存器重命名(register renaming)
    * 延迟(lantency), 表示完成运算所需要的总时间
    * 发射时间(issue time), 表示两个连续的同类型运算之阐需要的最小时钟周期数
    * 最大吞吐量, 定义为发射时间的倒数
    * 容量(capacity), 表示能够执行该运算的功能单元的数量.

8. 循环展开
- 循环展开, 并不是由C循环翻译成汇编的方式
- a. 减少不直接有助于程序结果的操作的数量, 如循环索引计算和条件分支
- b. 减少整个计算中关键路径上的操作数量
- GCC 优化等级3或更高等级, 就会执行循环展开

9. 提高并行性
- 多线程编程会提高性能, 多线程编程也会增加开销, 平衡点在哪里?
- a. 多个累积变量
- b. 

10. 优化合并代码的结果小结
- 合并代码指得是什么? 为何这里有个小结
    * 重新结合变换， 如将循环二次遍历合为一次, 能够减少关键路径上操作的数量
    * 用向量指令达到更高的并行度
    * 多项优化技术, 非常程式化的方式

11. 一些限制因素
- 限制因素有哪些? 硬件层面, 软件层面, 客观人力?
- 寄存器溢出
    * x86-64 有足够多的寄存器， 大多数循环在出现寄存器溢出之前就将达到吞吐量限制
- 分支预测和预测错误惩罚

12. 理解内存性能
- 内存性能指标是什么?
    * 高速缓存区
    * 加载的性能, 依赖于流水线的能力， 也依赖于加载单元的延迟
    * 存储的性能

- 有何优化手段
    * 

13. 应用: 性能提高技术
- 实际应用
- 高级设计. 为遇到的问题选择适当的数据结构和算法
- 基本编码原则.
    * 避免优化限制的因素， 依靠编译器才能产生高效的代码
    * 消除不必要的内存引用. 引入临时变量来保存中间结果。 
- 低级优化. 结构化代码以利用硬件功能 
    * 展开循环, 降低开销
    * 通过使用多个累加变量和重新结合等技术， 找到方法提高指令并行
    * 用功能性的风格重写条件操作（三目运算符？：）， 使得编译器采用条件传送数据

14. 确认和消除性能瓶颈
- 实战? 
- 代码剖析程序( code profiler)
    * gprof 工具
- Amdahl定律

15. 小结
- 性能优化方面:
    1. 主要目的就是减少所有指令执行的时钟周期
    2. 一个是 寄存器=堆栈 >= 内存 的访问速率
    3. 循环里减少计算量, 减少函数调用
    4. 函数会妨碍编译器优化, 编译器对于函数的优化, 都是以最糟糕的情况来假设, 这样稳妥保证不出错

## 存储器层次结构
1. 简单了解一下， 以便于有个概念
- 高速缓存器的工作原理
- 编写代码， 怎么控制高速缓存器呢？
- 如何应用在实战上， 买电脑时， 有没有参考呢？

2. 存储技术
- SRAM, DRAM, ROM
- 高速缓冲区对程序的性能影响最大
- 双稳态电路特性, 但得有电
- 内存系统必须周期性地通过读出，然后重写来刷新每一位内存
- 纠错码， 多编码几位
- 内存控制器
- 磁盘原理, 转速，盘面， 磁道， 扇区， 备用扇区
- 总线， 是一个简单的抽象， 可以具体描述但又不必和某个系统的细节联系过于紧密
- 内存映射
- 磁盘读取过程: 
    CPU 发送指令到磁盘控制器 -> 磁盘控制器将扇区读到主存(DMA, 直接内存访问) -> 硬盘控制器以中断通知cpu 
- SSD
    * 数据是以页为单位读写的
    * 只有在一页所属的块整个被擦除后，才能写这一页
    * 一旦一个块被擦除后， 块中的每一个页都可以不需要再进行擦除就写一次
    * 在大约100 000 次重复(擦除）写之后, 块就会磨损坏

3. 局部性
- 局部性： 倾向于引用邻近于其他最近引用过的数据项的数据项， 或者最近引用过的数据项本身
- 时间局部性， 空间局部性
    * 在不远的将来， 会再被多次访问数据
    * 在不远的将来， 会再被卧多次访问该数据附近的一个内存位置
        二维数组遍历， 按行列遍历， 具有空间局部性
- 重复引用相同变量的程序具有良好的时间局部性
- 对于具有步长为 k 的引用模式的程序， 步长越小， 空间局部性越好
- 对于取指令来说（不改变数据),循环具有良好的时间和空间局部性

4. 存储器层次结构
- 寄存器 > 高速缓冲区 > 内存 > 本地磁盘 > 远程分布式磁阵列
- 高速缓存， 缓存命中， 缓存不命中
    * 在第k层不命中的时候， 向第k+1取数据， 复制到k层， 然后下一次就可以继续从k层命中
    * 替换/驱逐, 牺牲块, 替换策略
    * 强制不命中/冷命中， 放置策略, 冲突不命中, 容量集， 容量不命中

5. 高速缓存存储器
- 讲述实现原理， 暂时略过
- 抖动: 调整缓存反复地加载和驱逐相同的高速缓存块的组
    * 抖动造成冲突不命中

6. 编写高速缓存友好的代码
- 让最常见的情况运行得快
- 尽量减小每个循环内部的缓存不命中数量
    * 对局部变量反复引用是好的
    * 步长为1的引用模式是好的
- 存储器山
    * 以不同的size(时间局部性) 和 stride(空间局部性) 的值组件的函数(测量和计算读吞吐量)图

7. 小结
- 

## 链接
1. 编译时， 加载时， 运行时， 链接器， 分享编译
- 有助于构造大型程序
- 避免一些危险的编程错误
- 语言的作用域规则是如何实现的
- 其他重要的系统概念
- 利用共享库

2. 编译器驱动程序
- 依次执行 cpp（C预处理器), ccl(C编译器), as(汇编器), ld(链接器), 创建一个可执行目标文件
- shell 调用操作系统中的加载器, 将可执行文件中的代码和数据复制到内存取，然后控制转移到这个程序的开头

3. 静态链接
- 符号解析 
    symbol resolution
- 重定位
    relocation

4. 目标文件
- 可重定位目标文件
- 可执行目标文件
- 共享目标文件
- 目标文件，目标模块，等同于一个概念
    a.out, 
    portable executable, 
    match-o, 
    executable and linkable format

5. 可重定位目标文件
- elf 文件格式
    .text
    .rodata
    .data
    .bss
    .symtab
    .rel .text
    .rel .data
    .debug
    .line
    .strtab

6. 符号和符号表
- 由模块m定义并能被其他模块引用的全局符号
    非静态C函数和全局变量
- 由其他模块定义并被m模块引用的全局符号
    非静态C函数和全局变量
- 只被模块m定义和引用的局部符号
    带static 的C函数和全局变量

7. 符号解析
- 强定义, 弱定义
    全局且初始化的变量和函数 为强， 反之为弱
- linux处理规则：
    * 不允许有多个同名的强符号
    * 如果有一个强符号和多个弱符号同名， 选择弱符号
    * 如果有多个弱符号同名， 任选一个
- gcc -fno-common 告诉编译器，遇到多重定义的全局符号时，触发一个错误
- -Werror 会将所有的警告都变为错误
- 与静态库链接
    * 静态库是为了解决代码利用问题，从编译器实现复杂度与磁盘空间浪费度综合考虑的产物
    * 静态库是存档文件
    * 链接器只复制用到的代码到可执行程序
    * 从左到右解析, 所以静态库如果有依赖关系， 顺序不可以乱
        >a. 重复库
        >b. 声明引用一定要出现在定义之前

8. 重定位
- 重定位节和符号定义
    * 将所有相同类型的节合并为同一类型的新的聚合节
- 重定位节中的符号引用
    * 指向正确的运行时地址
    * 重定位条目放在 .rel .text 节中
    * 相对地址， 绝对地址
- 链接器每一步做得事都足够简单， 但是组合到一起， 效果就很神奇

9. 可执行目标文件
- 按节的顺序排列的二进制数据格式
- 将程序复制到内存并运行的过程叫做加载
- 程序的开始地址和栈的开始地址一般都是固定的，固定不用怕栈溢出吗？
- 所谓内核就是操作系统驻留在内存的部分，不会被释放
- 内存总是一种稀缺资源， 不论系统内存有多大

10. 动态链接共享库
- 动态链接器
- 允许多个正在运行的进程共享内存中相同的库代码， 因而节约宝贵的内存资源

11. 从应用程序中加载和链接共享库
- 是一项很牛逼的技术， 典型例子是web服务器, 将fork的开销变成函数的动态调用开销
- jni， 是动态链接和加载的典型例子

12. 位置无关代码
- 多个进程是如何共享程序的一个副本的呢？
- PIC, Position-Independent Code
- -fpic 共享库的编译必须总是使用该选项, 那为何不做成默认的呢？
- 数据段与代码端的距离总是保持不变, 相对寻址技术
- GOT, Global Offset Table
- 延时绑定，lazy binding
    将过程地址的绑定推迟到第一次调用该过程时
- 过程链接表, PLT, Procedure Linkage Table

13. 库打桩机制
- aop 的思想
- 给定一个需要打桩的目标函数， 创建一个包装函数， 它的原型与目标函数完全一样。 使用某种特殊的打桩机制， 就可以欺骗系统调用包装函数而不是目标函数了
- 编译时 
    -DCOMPILETIME, -I
- 链接时 
    -DLINKTIME, --wrap f
- 加载运行时
    LD_PRELOAD

14. 处理目标文件工具
- ar: 创建静态库， 插入，删除， 列出和提取成员
- string: 列出一个目标文件中所有可打印的字符串
- strip: 从目标文件中删除符号表信息
- nm: 列表一个目标文件的符号表中的定义的符号
- size: 列出目标文件夹中节的名字和大小
- readelf: 显示一个目标文件夹的完整结构， 包含size和nm功能
- objdump: 所有二进制工具之母。 能够显示一个目标文件中的所有信息. 是大作用是反汇编.text节中的二进制指令。
- ldd: 列出一个可执行文件在运行是所需要的共享库

15. 小结
- 如何编译出.o 文件？

## 异常控制流
0. 控制转移， 控制流, 突变(异常控制流, Exceptional Control Flow, ECF)
- 重要的系统概念
- 应用程序如何与操作系统交互的
- 编写有趣的新应用程序
- 理解并发
- 软件异常如何工作

1. 异常
- 异常是异常控制流的一种, 控制流中的突变， 用来响应处理器状态中的某些变化。
- 异常表, 异常处理程序(exception handler)
- 处理器设计者分配的： 缺页， 被零除，内存访问违例，断点及算术去处溢出。
- 操作系统内核设计者分配的：系统调用， 外部I/O设备的信号
- 异常的分类： 中断(interrupt), 陷阱(trap), 故障(fault), 终止(abort)
- 虚拟程序引用一个未定义的虚拟内存区域， 一般保护故障报告为"段故障"(Segmentation fault)
- 系统调用: 读/写文件， 创建一个新的进程, 系统调用同样对应内核中的跳转表

2. 进程
- 异常是允许操作系统内核提供进程(process)概念的基本构造块
    基本构造块是什么？ 进程还有哪些构造块
- 独立的逻辑控制流
    指令值(PC)序列
    每个进程还是共享CPU时间片
- 并发流
    并发， 多个流并发地执行
    多任务， 一个进程和其他进程轮流运行
    时间片, 多任务也叫 时间分片
    并发流的思想与流运行的处理器核数或者计算机数无关， 如果两个流在时间上重叠， 那么它们就是并发， 即使它们运行在同一个处理器上。
    并行流， 两个流同时运行在不同的处理器, 是并发流的一个真子集

- 私有的地址空间
    内核虚拟内存： 数据, 代码， 堆，栈
    用户栈
    共享库的内存映射区域
    运行是堆(malloc)
    读/写段(.data, .bss)
    只读代码段(.init, .text, .rodata)
- 用户模式和内核模式 
    * 进程从用户模式变为内核模式的唯一方法是通过诸如中断， 故障或陷入系统调用的这样的异常。当异常发生时， 处理器将模式从用户模式变为内核模式。 处理程序运行在内核模式中， 当它返回到应用程序代码时， 处理器就从内核模式改回到用户模式
    * /proc文件系统， 允许用户模式访问内核数据结构的内容。 后引入/sys文件系统， 输出关于系统总线和设备的额外的低层信息.
- 上下文切换
    * 进程调度

3. 系统调用错误处理
- 当Unix系统级函数调用出错时， 会返回-1, 并设置全局变量errno来表示出了什么错了。
    errno, 在OpenGL编程的时候遇到过

4. 进程控制
- 每个进程都有一个唯一的正数进程pid
- 程序员的角度， 进程的三种状态：
    * 运行。要么在CPU上执行， 要么在等待被执行且最终会被内核调度
    * 停止。进行执行被挂起， 且不会被调度。直到它收到了SIGCONT信号， 会再次开始运行。
    * 终止。进程永远地停止了。
- fork 函数 
    * 一次调用， 两次返回， 在父进程中返回子进程PID， 在子进程中返回0, 因为进程号为正数， 因此可以区分fork是运行在父进程还是子进程。
    * 并发执行。 父进程和子进程是并发运行的独立进程。
    * 相同但是独立的地址空间
    * 共享文件。
- 回收子进程
    * 进程由于某一原因终止时， 进程被保持在一种已终止的状态中， 直到被它的父进程回收(reaped)。一个终止了但还未被回收的进程称为僵死进程。
    * 如果一个父进程终止了， 内核会安排init进程成为它的孤儿进程的养父。init进程不会被终止， 是所有进程的祖先
- waitpid, wait函数
- 让进程休眠 sleep
- execve, 加载并运行可执行目标文件，调用一次从不返回
- 

5. 信号
- 一个信号就是一条小消息, 通知进程系统发生某一类事件
- 发送信号
    * /bin/kill 发送信号 /bin/kill -9 (-)pid 向pid(进程组的每个)进程发送一个SIGKILL的信号
    * 键盘发送信号, ctrl+c, ctrl + z
    * alarm 函数发送信号
    *
- 接收信号
    * 一种类型最多有一个待处理信号， 一个待处理信号最多被接收一次
    * 当内核把p内核模式转换到用户模式的时， 它会检查p进程的未被阻塞的待处理信号集合， 如果集合非空， 内核会选择集合中的某个信号k(通常是最小的k)， 并强制进制p接收信号k。 收到这个信号就会触发某种行为， 一旦进程完成了这个行为， 控制就会传递回 p 的逻辑控制流的的下一条指令。 
    * 每一个信号都有一个预定义的默认行为
        > 进程终止(SIGKILL); 进程终止并转储内存(); 进程停止（挂起）直接到被 SIGCONT 信号重启; 进程忽略该信号(SIGCHILD)
        > SIGSTOP, SIGKILL 的置信行为是不能修改的
- 阻塞和解除阻塞信号
    * 显式阻塞机制
        应用程序可以使用 sigprocmask 函数和它的辅助函数， 明确地阻塞和解除选定的信号
    * 隐式阻塞机制
        内核默认阻塞任何当前待处理程序正在处理信号类型的待处理信号
- 信号处理程序
    * 信号处理程序和主程序以及其他信号处理程序并发地运行， 与主程序并发地访问全局的数据结构
    * 安全的信号处理
        > G0, 处理程序要尽可能简单
        > G1, 在处理中只调用异步信号安全的函数(要么是可重入的[只访问局部变量], 要么不能被信号处理程序中断[系统级函数])
        > G2, 保存和恢复errno
        > G3，阻塞所有信号， 保护对共享全局数据结构的访问
        > G4, 使用volatile声明全局变量
        > G5, 用 sig_atomic_c 声明标志
        > 都是多线程安全的套路
    * 正确的信号处理
        > 
        > 未处理的信号是排除的， 因为pending位向量中的每种类型的信号只对应有一位
    * 可移植的信号处理
        > 系统遗留问题， 不同的系统有不同的信号处理定义 
        > 信号处理函数包装函数
    * 同步流以避免讨厌的并发错误
        > 并发编程是一个考验智力的领域 
    * 显式的等待信号
        > 阻塞的原理是什么？ 等待可以使用循环
        > 进程挂起， 可以理解成内核层的回调？ 
        > 

6. 非本地跳转
- 用户形式的异常控制流形式
- setjmp, 在env缓冲区保存当前调用环境
- longjmp, 从env缓冲区恢复调用环境, 
- longjmp 可以从深层嵌套调用中返回setjmp，而不需要解开整个栈的基本框架， 这可能会导致意外的后果， 后面释放资源代码未被执行， 产生内存泄漏
- c++ 和java 中的软件异常是较高层次的， 是C语言的setjmp和longjmp函数的更加结构化版本，
    可以简单地类比, catch -> setjmp, throw -> longjmp

7. 操作进程的工具
- ps, top, strace, pmap, 都可以能过man 来学习

8. 小结
- 异常类型: 中断，故障，终止和陷阱(回调？)
- 最开始以为异常的实现就是硬件层的中断，异常类型的中断跟中断方式表述的不是同一个意思
- 异常控制流(ECF) 发生在计算机系统的各个层次， 是计算机系统中提供并发的基本机制。

## 虚拟内存
> 硬件异常， 硬件地址翻译，主存，磁盘文件和内核软件的完美交互, 为每个进程提供一个大的， 一致的和私有的地址空间
1. 物理和虚拟地址
- 物理寻址, CPU访问内存的最自然的方式就是使用物理地址
- 虚拟寻址, 虚拟地址(VA, Virtual Address), 内存管理单元(MMU, Memory Management Unit)
    利用存放在主存中的查询表来动态翻译虚拟地址， 该表的内容由操作系统管理
- 计算机中有太多这样的中间单元来作为代理角色，统一接口，操作方式 

2. 地址空间
- 一个地址空间大小是由表示最大地址所需要的位数来描述的, 2^n
- 物理内存大小不要求是2的幂

3. 虚拟内存作为缓存的工具
- 虚拟页， 物理页(PP, Physical Page), 有固定大小， 物理=虚拟
    物理页数和虚拟页数相等吗? 不一定， 物理地址可以是主存， 也可以是磁盘， 虚拟的只需要记录物理的起始位置， 就可以使用, 那样的话， 物理哪些页使用完了该怎么记录呢？
    虚拟>=物理（仅限于主存，不算磁盘的)
- PTE(Page Table Entry), 由一个有效位和一个n位地址字段组成的
    有效位表明了该虚拟页当前是否被缓存在DRAM中 
- 页表就是一个页表条目数组， 大小为最大寻址数/每页大小(2^n / 2^p = 2^(n-p)), 最大寻址是按地址位数(总线位数)， 物理理论上没有限制， 因为还有磁盘, 但是虚拟内存>=物理主存, 最主要操作还是在主存上
    早期的虚拟地址小于主存， 但是仍然有意义， 简化了内存管理
- DRAM缓存(主存)是全相联的， 是什么意思, 物理页可以和任意虚拟页相联
- 页命中, 缺页（不命中), 按需页面调度(demand paging)
- 抖动， 工作集的大小超期出了物理内存的大小, 页面将不断地换进换出

4. 虚拟内存为内在管理的工具
- 操作系统为每一个进程提供了一个独立的页表, 因而也就是一个独立的虚拟地址空间
    多个虚拟页面可以映射到同一个共享物理页面上, 每个进程的内存中间有一段对齐的空白
- VM简化了链接和加载， 代码和数据共享， 以及应用程序中的内在分配
- 简化链接
    独立的地址空间允许每个进程的内存映像使用相同的格式, 而不管代码和数据实际存放在物理内存何处.
- 简化加载
    虚拟内存系统会按照需要自动调入数据页
    内存映射， 将一组连续的虚拟页映射到任意一个文件夹中任意位置的表示法
- 简化共享
    每个进程不共享的数据, 被操作系统将虚拟页映射到不连续的物理页面, 共享的代码和数据(如标准库中的程序)通过将不同进程中适当的虚拟页面映射到相同的物理页面, 从而安排多个进程共享这部分代码的一个副本, binder机制就是怎么识别这样的共享区域？
- 简化内存分配
    操作系统可以保证虚拟内存连续， 物理内存没必要连续， 而虚拟内存是对用户可见的
- 小结： 虚拟内存对用户可见， 用户可以是链接器， 也可以是程序员编写的应用， 而操作系统主要来维护虚拟表与物理表的映身操作， 而这种操作也是通用的，功能单一的， 可是真正要注意的东西挺多， 已使用的物理内存映射查询， 共用的物理内存， 所以，这套系统是复杂精密的， 功能单一是从宏观操作上来说， 抽取所有内存管理的通用部分

5. 虚拟内存作为内存保护工具
- 带有许可位的PTE
- 违反了许可条件， CPU触发一个保护故障， 将控制传递给内核中的异常处理程序， 报告为"段错误(segmentation fault)"

6. 地址翻译
- 基本参数
    * N = 2^n, N 为最大虚拟内存容量， n 为地址位数
    * M = 2^m, M 为最大物理内存容量， m 为地址位数
    * P = 2^p, P 为页的大小(字节),  n-p 为虚拟页号位数
- 虚拟地址(VA)
    * VPO, 虚拟页面的偏移量
    * VPN, 虚拟页号
    * TLBI, TLB(翻译后备缓冲器, translate lookaside buffer)索引
    * TLBT, TLB 标记
- 物理地址(PA)
    * PPO, 物理页面偏移量
    * PPN, 物理页号
    * CO, 缓冲块内的字节偏移量
    * CI, 调整缓存索引
    * CT, 调整缓存标记
- 结合高速缓存和虚拟内存
    * 大数多系统是选择物理寻址
    * 地址翻译发生成高速缓存查找之前
- 多级页表
    * 不管是一级页表还是二级页表， 都是在主存中存储的, 
    * 如果一级页表为空, 二级页表就为空， 内存大部分是空状态的
    * 一级PTE， 二级PTE， 页表大小都为4k, 这为何就减小了内存要求？ 
    * 是因为PTE也是存储在物理页表中的， 而物理页表又是与虚拟页表对应的？
    * 各自完成自己最简单的事， 然后将各自的能力组合起来， 就可以完成一件复杂的事， 计算机将这种机制完美呈现
- 综合， 端到端的地址翻译
    * 具体实例， 后面再细看, 还真被卡在这里了？ 这也不看， 那也不看， 看完这一章， 还是不清楚到底讲了啥
    * 不要看电影了， 还有半小时， 可以将这个实例看完
    * VPN并不存储在主存中，是虚拟计算出来的值
    * 一个虚拟地址由 VPN + VPO组成， VPO的位数， 是用来表示当前页的位置， VPN是用来指示页数，相对于整个虚拟内存来说， 物理地址同理
    * PPO 与 VPO 是保持一致的， 所以 VPO的值就是PPO的值, 
    * VPN 再分为 TLBT, TLBI， 用来映射到TLB， tag 是用来区别映射到同一个 TLB组， 不同的vpn， tag值都是真实的物理地址， 按位的定义取得的， 所以， 具有区分性, 虚拟地址可以比物理地址大， 因此
    * 物理地址对应于高速缓存再分为 CT, CI, CO 
    * 高速缓存 16个组 * 4字节块 = 64KB; CO: 针对4字节块的偏移量,  CI针对 16个组， CT对应于TLBT， 那么一个高速缓存的能力是多少呢？就是14位的物理地址？ 
    * 整个翻译流程： 
        > cpu -> mmu -> 高速缓存 -> (主存)内存 -> 磁盘
        a> cpu 产生一个虚拟地址VA(VPN + VPO) 送到mmu
            cpu 怎么产生一个虚拟地址呢？ 统一的进程内存模型, 由编译器来分配, cpu只是简单地加载
        b> mmu 生成PTE地址，并向高速缓存/主存请求得到它
            mmu 根据VA 中的VPN 来选择PTE, vpn0 <->pte0 这个规则是谁定的呢？ 编译器根据各平台确定的，就按vpn0<->pte0 一一对应映射是最简单方便的，但是还有提升空间， 就是多级页表
            vpn>=pte, 在物理内存不足的情况下， 各系统有各自的处理, linux通过swap, windows试着回收一下内存, 要是还不够，只能杀死当前程序
        c> 高速缓存/主存向MMU返回PTE(命中的情况下)
        d> 上一步不命中， 触发缺页处理程序(cpu控制操作系统内核) 
            确定出物理内存中的牺牲页， 如果这个页面修改了， 则把它换出磁盘， 调入新的页面内容覆盖此内存区域， 以及PTE条目, 返回原来的进程， 再次执行导致缺页的指令, 此是必命中
        e> MMU根据PTE构造物理地址, 并把它传送给高速缓存/主存
        f> 高速缓存/主存返回所请求的数据字给CPU
            说明高速缓存/主存也有控制芯片， 以供寻址，读写操作 
            高速缓存/主存的容量岂不是要打折扣？ 高速缓存是直接将物理地址PA切分， 按着hash算法的思想， 缓存主存中的值
            高速缓存是按组和块来布局的，切分整个PD 分为CT(标记), CI(组索引), CO(块索引), 与TLB类似, TLB是将VPN切分.
        g> 使用TLB加速地址翻译
            MMU中包含了一个关于PTE的小的缓存TLB(Translation Lookaside Buffer), PTE的缓存思想与CPU的缓存思想一致，降低PTE缺页损失. 
            TLB是MMU的高速缓存， 只缓存PTE, 是按块来分的, 块的位数为TLBI, 剩下的VPN位数-块位数来表示TLBT, 经高速缓存少了组的概念
            L1,L2,L3是CPU的高速缓存， 用来缓存主存的值; MMU通过VA，可以翻译成PA, 再将PA按hash思想， 映射到高速缓存中比对， 对上了就是缓存成功
        h> 多级页表
            PTE是缓存在主存中的，多级页表可以减少页表缓存的浪费, 同时也可以加快查找速度， 类似于二分法， 这里多级是均分法, 减少主存查找次数的压力.
            使用4字节的PTE， 每个一级页表和二级页表都是4KB字节，(一级PTE = 1024 * 二级PTE, 二级PTE = 物理页) 是为了保存和页面的大小一样. 这只是示例中解说， 实际实现主要是对齐思想. 
        i> 综上， 主要的关键点： TLB 缓存PTE， 通过PTE， 可以算出PA, 再将PA切分hash到高速缓存比对， 组，偏移， tag对上了， 高速缓存的值就是PA所存储的值, 所以，物理地址和值就对应上了 
 
7. Intel Core i&/Linux内存系统
- 48位的虚拟地址， 可映射256TB的内存， 40位的物理地址, 传输还是使用64位， 带有状态标志
- 四级PTE， 每一级PTE保持4KB对齐, 4KB * 4KB * 4KB * 4KB = 256TB
- 内核管理缺页处理程序， 内核可以访问任意物理地址， 是因为有一段虚拟地址与所有的物理地址一一映射, 缺页程序的非法操作: 段错误，保护异常
 
8. 内存映射
- 虚拟页面初使化: cpu第一次引用，实际交换进入物理内存
- 二进制零的区域， 匿名文件映射
- swap space, 在任何时刻， 交换空间都限制着当前运行着的进程能够分配的虚拟页面的总数
    linux将所有的设备都解释成文件, 主存/内存对应的文件角色就是swap file, 当然这个swap file还可以比内存/主存大， 这个时候， 临时使用磁盘空间
- 共享区域， 私有区域: 一个对象映射到虚拟内存的角色
- 写时复制(copy on write)最充分地使用了稀有的物理内存
- mmap 函数的编写, 创建，删除虚拟内存区域

9. 动态内存分配
- malloc, calloc, ralloc, free
- 分配器的要求
    * 处理任意请求的序列
    * 立即请求响应
    * 只使用堆 
    * 对齐块， 使得它们可以可以保存任何类型的数据对象。 为什么对齐了就可以保存任意类型的数数据对象？ 对齐之后， 便于寻址， 按数据类型大小， 读字节， 跟解析协议的时候思路是一致的。
    * 不修改已分配的块
- 目标
    * 最大化吞吐率
        单位时间里完成的请求数
    * 最大化使用率: 
       峰值利用率
       有效载荷 payload, 聚集有效载荷 aggregate payload
- 碎片
    * 内部碎片, internal fragmentation
        已分配块大小和它们的有效载荷大小之差的和
    * 外部碎片, external fragmentation
        当空闲内存合计起来足够满足一个分配请求， 但是没有一个单独的空闲块足够大可以来处理这个请求时发生的。
- 实现问题
    * 空闲块组织
        + 块大小总是8的倍数， 最低3位总是0 ，因此可以释放这三位来编码其他信息， 真妙, 只需要将大小 |  0x后三位
    * 放置
        + 首次适配first fit， 下一次适配next fit, 最佳适配best fit
    * 分割
        + 策略决定，选择整个空闲块， 或者将空闲块分割为两部分
    * 合并
        + 假碎片(fault fragmentation), 立即合并， 推迟合并
        + 边界标记(boundary tag)
        + 最小块大小： 最小已分配块大小和最小空闲块大小两者的最大值

- 隐式的空闲链表
    * 感觉可以作为炼妖打书的参考
    * 对齐的作用： 便于根据offset寻址, 像8的倍数， 可以留出3位使用, 便于存放任意的对象
    * 对齐的缺点： 空间浪费
- 显式的空闲链表
    * 块分配与堆块的总数呈线性关系， 所以隐式空闲链表是不合适的
    * 堆可以组成成一个双向的空闲链表， 在每个空闲块中， 都包含第一个pred(前驱)和succ(后继)指针
    * 后进先出(LIFO)， 最先检查最近使用过的块， 释放和合并一个块可以在常数时间内完居
    * 按照地址顺序来维护链表，平衡点在于，按照地址排序的首次适配比LIFO排序的首次适配有更高的内存利用率, 最近最佳适配利用率
    * 缺点： 空闲块必须足够大， 也潜在地提高了内部碎片的程度。
- 分享的空闲链表
    * 分享存储segregated storage
    * 维护多个空闲链表， 每个链表中的块大致相等， 等价类（大小类）
    * 首次适配搜索
    * 伙伴系统 buddy system, 
    *
-
10.垃圾收集 
- Lisp 祖先级别, John McCarthy
- 有向可达图 reachability graph

11. C程序中常见的内存有关错误
- 间接引用环指针, scanf("%d", &val), 如何传变量， 也将当成一个地址解析， 现在编译都会报错， 但是不报错的情况下， 就会覆盖val值所代表的地址里的内容
- 读未初始化的内存
    bss内存位置（未初始的全局C变量）总是被加载初始化为零， 但是对于堆内存却不是这样
- 允许栈缓冲区溢出
- 假设指针和它们指向的对象是相同的大小
- 造成的位错误, 错位off-by-one
- 引用指针， 而不是它所指的对象
- 误解指针运算， 指针的算术操作是以它们指向的对象的大小为单位来进行的
- 引用不存在的变量, 返回一个局部变量的地址
- 引用空闲堆块中的数据
- 引起内存泄漏

12. 小结:
- 后面的有点赶时间，大致少了一遍， 也是有作用的，至少能知道虚拟内存这一章讲什么 
- 虚拟内存就是在讲整个内存的使用规则，对主存的一个抽象，有了虚拟内存的机制， 对于操作系统来说， 管理内存更方便, 内存结构更统一，剩下的就是讲虚拟内存与物理内存的映射机制，通过mmu(内存管理单元), 命中不命中异常处理，异常的知识也没来得急看, 这些都得看
- 虚拟内存，再抽象一层通用的, 进程内存空间模型 
- 异常也得找机会看， 结合问题， 面试题， 应用场景， 编程经历来理解，看这本书， 中间总是容易陷入 大脑无意识状态的读下去， 看了很多细节都不知道再讲什么， 然后理解了一些细节的原理， 但是对于整章讲什么， 学到了什么， 还是说不出来
- 这不仅仅是对 C 程序有用, 对整个编程语言的思想都有用，进程内存模型，内存碎片， 垃圾回收
- 看完之后， 对编程有什么帮助， 能否印证编程语言为什么那样设计， 理解编程的内含
- 地址翻译原理： 之所以有些难以理解， 还是那些缩写术语不熟悉, 多看几遍之后，了解术语是基础，然后再解决整个流程的疑问
- 强制性地看完了， 有什么收获呢？ 对进程的内存模型的前因后果有一个了解，高速缓存的作用， cpu, mmu的协作翻译地址的过程, c语言的内存操作， malloc, free, 自动回收机制语言.
- 虚拟内存的高效性， 从哪里来， 考虑哪些因素? 加快翻译速度， 节奏稀有的物理内存资源。
- 虚拟内存提供三个重要的功能： 
    a. 在主存中自动缓存最近使用的存放在磁盘上的虚拟地址空间的内容。
    b. 虚拟内存简化了内存管理， 进而又简化了链接、在进程间共享数据、进程的内存分配以及程序的加载。
    c. 虚拟内存能过在每条页表条目中加入保护位， 从而简化了内存保护
- 

## 系统级I/O
0. 知识回顾
- I/O是每种语言都必不可少的， 每种语言都封装好了I/O函数， 感觉使用上并不难, 因此也一直没有重视起来!
- 让我总结一下， 对I/O有何也解， 也是不清楚， 读取文件， 读取目录， 创建文件和目录， I/O流， 封装格式化的I/O流
- linux下一切皆文件， 因此也可看出I/O的重要性
- 打开和关闭文件，有何注意的地方， 流要及时关闭？ 阻塞和非阻塞
- RIO，又是如何健壮地读写呢
- 文件元数据又是什么, 目录和内容里又有何骚操作?
- 共享文件是如何实现的， 多少读写， 肯定涉及到多线程
- I/O重定向, >  >> 重定向符号， 配合pipe， 目前重定向了解的也就这些
- 标准I/O, 非标准I/O又是什么？
- 所有语言“运行时系统”都提供较高级别的I/O函数

1. Unix I/O
- 了解 Unix I/O将会帮助理解其他系统概念
- 有时除了使用Unix I/O外， 无其他选择
- 要理解I/O， 必须要了解进程， 反之易然
- 所有的I/O设备都被模型化为文件， 而所有的输入， 输出都被当作相对应的文件的读和写来执行。
- 对于每个打开的文件， 内核会保持着一个文件位置k. 无论任何一进程因为何种原因终止时， 内核都会关闭所有打开的文件并释放它们的内存资源.
- 打开文件, linux shell 创建的每个进程开始时都有三个打开的文件， 改变当前文件位置， 读写文件， 关闭文件。

2. 文件
- 普通文件
- 目录
- 套接字

3. 打开和关闭文件 
- 三个打开的文件(描述符)：stdin(0), stdout(1), stderr(2)

4. 读和写文件
- 不足值(short count): read, write 传送的字节比应用要求的要少。
- 读时遇到EOF
- 从终端读文本行
- 读和写网络套接字
- 通过反复read, write处理不足值

5. 用RIO包健壮地读写
- Robust I/O
- 无缓冲的输入输出函数
    * 二进制数据 <-> 网络
- 带缓冲的输入函数

6. 读取文件元数据
- Metadata returned by the stat  and fstat functions
    struct stat{
        dev_t           st_dev;     /* Device */
        ino_t           st_ino;     /* inode  */
        mode_t          st_mode;    /* Protection and file type */
        nlink_t         st_nlink;   /* Number of hard links */
        uid_t           st_uid;     /* User ID of owner */
        gid_t           st_gid;     /* Group ID of owner */
        dev_t           st_rdev;    /* Device type (if inode device) */
        off_t           st_size;    /* Total size, in bytes */
        unsigned long   st_blksize; /* Block size for filesytem I/O */
        unsigned long   st_blocks;  /* Number of blocks allocated */
        time_t          st_atime;   /* Time of last access */
        time_t          st_mtime;   /* Time of last modificateion */
        time_t          st_ctime;   /* Time of last change */
    }

7. 读取目录和内容
- 目录流(directory stream)
- opendir, readdir, closedir

8. 共享文件
- 内核使用三个相关的数据结构来表示打开的文件
    * 描述符表(descrition table), 每个打开的描述符表项指向文件表中的一个表项
    * 文件表(file table), 打开的文件的集合是由一张文件表来表示的， 所有的进程共享这张表。
        文件位置， 引用计数， v-node指针
    * v-node表， 所有进程共享这张表
        包含stat结构中的大多数信息

9. I/O重定向
- int dup2(int oldfd, int newfd);

10. 标准I/O
- 标准I/O库将一个打开的文件模型化为一个流。 对于程序员而言， 一个流就是一个打向FILE类型结构的指针。 

11. 我该使用哪些I/O
- 只要有可能就使用标准I/O
- 不要使用scanf或 rio_readlineb 来读二进制文件
- 对网络套接字的I/O使用RIO函数

12. 小结
- 本章介绍的并不多，标准库的函数解释
- 不足值要处理， 建议使用RIO， 记住使用哪个I/O的选择 i
- 文件共享，涉及到三个概念: 文件描述符， 文件表， v-node表 
    v-node表只有一个实例，文件表是每个进程在创建一个文件的时候在内核中注册的， 可以有多个文件表项指向同一个v-node表项, 代表文件共享 ， 文件描述符就是对应文件表项的索引.

## 网络编程
1. 客户端-服务端编程模型
- 客户端和服务端都是进程， 可以在同一个主机上， 也可以在不同的主机上， 不管是什么情况，客户端-服务端的模型都是相同的。
- 一个服务端进程和多个客户端进程， 所以一台主机可以同时运行多个不同的客户端和服务端
- 客户端-服务端模型中基本操作是事务， 此事务跟数据库中的事务不一样， 仅仅是指交互流程的一系列步骤

2. 网络
- 以太网，集线器不加分辨地将从一个端口上收到的每个位复制到其他所有的端口上。 每个主机都可以看到帧， 但是只有目的主机实际读取它。
- 网桥，可以桥接以太网， 用于构建较大的局域网。
- 路由器， 更高层次级别中的特殊计算机， 组成一个互联网络(internet)
- 不同的局域网技术有不同和不兼容的方式为主机分配地址。
- 互联网络思想的精髓， 封装是关键。不同协议， 不同的路由可以有不同的适配方式， 实现就是在路由上的协议软件。

3. 全球IP因特网
- TCP/IP
    * 协议族
    * 主机集合被映射为一组32位的地址
    * IP地址被映射为一组因特网名(Internet domain name)的标识符
    * 因特网主机上的进程能够通过连接和任何其他因特网主机通信。
- 网络字节序
    * 大端, big-endian, 网络字节序统一大端， 不管主机是否是小端,  和阅读顺序一致
    * 小端, little-endian, 有效地将地址的高低和数据位权结合起来。
- 因特网连接
    * 连接是点对点的, 全双工的
    * 一个套接字是连接的一个端点， 一个连接是由它两端的套接字地址唯一确定的。
    * 一个套接字对表示一个连接， 意味着， 只要两端的套接字对不一样， 就是不同的连接？

4. 套接字接口
- 客户端: getaddrinfo, socket, connect, rio_written, rio_readlineb, close
- 服务端: getaddrinfo, socket, bind, listen, accept, rio_readlineb, rio_written, rio_readlineb, close
``
/* IP socket address structure */
struct sockaddr_in  {
    uint16_t        sin_family; /* Protocol family (always AF_INET) */
    uint16_t        sin_port;   /* Port number in network byte order */
    struct in_addr  sin_addr;   /* IP address in network byte order */
    unsigned char   sin_zero;   /* Pad to sizeof(struct sockaddr) */
};

/* Generic socket address structure (for connect, bind, and accept) */
struct sockaddr {
    uint16_t sa_family;     /* Protocol family */
    char sa_data[14];     /* Address data */
}
``
- 监听描述符 listenfd, 已连接描述符 connfd
- int getaddrinfo(const char *host, const char *service, const struct addrinfo *hints, struct addrinfo `**result)
    函数将主机名， 主机地址， 服务名和端口号的字符串表示转化成套接字地址结构。
    为何得到的是 addrinfo 链表, char * host, char *service, 可以一次性传多个？
- int getnameinfo(const struct sockaddr *sa, socklen_t salen, char *host, size_t hostlen, char *service, size_t servlen, int flags);
    与getaddrinfo 功能相反， 将一个套接字地址结构转换成相应的主机和服务名字符串.
- 迭代服务器: echo客户端和服务端
- 并发服务器: 能够同时处理多个客户端
- EOF
    并没有像EOF字符这样的一个东西, 其实是由内核检测到的一种条件。
    read函数返回的零返回码时
    当前文件位置超出文件长度时
    一个进程关闭连接它的那一端时
    连接另一端的进程在试图读取流中最后一个字节之后的字节时

5. Web 服务器
- HTTP, 超文件传输协议
- MIME, Multipurpose Internet Mail Extensions, 多用途的网际邮件扩充协议
- CGI, Common Gateway Interface, 通用网关接口
    遵循CGI标准的程序都是CGI程序。

6. 综合： TINY Web 服务器
- 源代码，以及lab都下载好了， 待看完了， 一并写代码吧
- 源码肯定是得看， 得敲的，不然就是看完， 也不晓得看到了什么。\

7. 小结
- 克服了对服务器神秘的畏惧心理， 为何动态资源， 静态资源， 配置文件， 要那样搞， 这本来就是程序员的习惯行为， 这一行为也不得不被使用者（运维角色）接受
- 加深了文件系统， 文件描述符， 文件表，文件映射节点表
- 服务端， 客户端都是通过套接字连接，套接字对是每对连接的描述。
- 文件重定向， 可以实现通信， 所有的连系， 通过文件描述符， 文件描述符对应的是文件表的索引
-

## 并发编程

