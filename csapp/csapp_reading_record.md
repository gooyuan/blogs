
## 深入理解计算机操作系统

    Computer Systems - A Programmer's Perspective 
    是时候走一遍了, 有些细节先不深究, 如 float数据, 补码之类
    按顺序读, 太难的, 也先过... 如 处理器体系结构
    主要有个整体的概念, 然后捡感兴趣的章节先读
    优化程序性能, 虚拟内存, 异常控制流, 系统级I/O, 网络编程, 并发编程

## 1. 计算机系统漫游
####  位+上下文
1. 文本文件 和 二进制文件 
2. 上下文, 现在看来没啥疑问, 当初可是怎么都想不明白
3. 看不懂的书, 肯定是积累不够

####  程序
1. 翻译成各种形式的字节码
    > 预处理器 -> 编译器 -> 汇编器 -> 链接器
2. GNU环境 
    * EMACS编辑器, GCC编译器, GDB调试器, 汇编器, 链接器, 处理二进制文件的工具及其他一些部件
    * free
####  编译系统
1. 编译器是如何将代码转换成不同平台的机器语言
2. 优化程序性能
3. 理解链接时出现的错误
4. 避免安全漏洞

####  处理器解释指令 
1. shell 解释可执行程序
2. 系统的硬件组成
- 总线
    * 电子管道
- I/O设备
    * 每个I/O设备都通过一个控制器和适配器与I/O总线相连
    * 控制器和适配器的区别主要在于它们的封装方式
- 主存
    * DRAM (dynamic random access memory)
    * 即内存, 临时存储

- 处理器
    * 核心是一个大小为一个字的存储设备, 程序计数器(PC), 指向主存中的机器指令
    * 指令集架构, 微体系结构
    * 寄存器文件是啥, 存放几百字节, CPU 和 ALU各16个? 跟这还不一样, 专门设计的SRAM, 寄存器堆, 
####  高速缓存
1. 高速缓存 SRAM(static random access memory)
- 高速缓存的局部性原理

####  储存设备
1. 存储器层次结构
- 寄存器 > L1高速缓存 > L2 > L3 > 主存(DRAM, 内存) > 本地二级存储 > 远程二级存储

####  操作系统管理硬件 
1. 抽象概念
- 进程 
    * 对正在运行的程序的一种抽象
    * 上下文切换 
    * 线程
- 虚拟内存 
    * 为每个进程提供一个假象, 即独占地使用主存
    * 每个进程看到的内存都是一致的, 称为虚拟地址空间

- 文件
    * 字节序列, 仅此而已
    * 向应用程序提供了一个统一的视图, 来看待系统中可能含有的所有各式各样的I/O设备

2. 内核
- 内核管理管理进程上下文的切换
- 内核是常驻主存的部分
- 内核不是一个独立的进程, 是系统管理全部进程所用代码和数据结构的集合

####  网络通信
1. 网络也是一种I/O设备
2. 通过网络适配器完成机器间的数据复制 

####  重要主题
1. Amdahl 定律
- 要想显著加速整个系统, 必须提升全系统中相当大的部分的速度 
- 描述了改善任何过程的一般原则
- 整体与部分的关系

2.  并发和并行
- 并发 (concurrency) 是一个通用的概念, 指一个同时具有多个活动的系统
- 并行(parallelism) 指的是用并发来使一个系统运行得更快
- 线程级并发
    * 在一个进程中执行多个控制流
    * 多核处理器
        * 每个核有各自的L1和L2高速缓存器, 共享更高层次的高速缓存
        * 从两个方面提高系统性能
        > 1. 减少了在执行多个任务时模拟并发的需要, (这里的模拟并发, 是分配时间片, 上下文切换的消耗么?)
        2. 可以使应用程序运行得更快, 前提是使用多线程编写
    * 超线程
        * 同时多线程(simultaneous multi-threading)
        * 一个CPU执行多个控制流的技术
- 指令级并行
    * 在较低层次的抽象上, 现代处理器同时执行多条指令
    * 超标量(super-scalar)处理器: 比一个周期一条指令更快的执行效率
    * 单指令, 多数据并行
3. 计算机系统中抽象的重要性
- 提供不同层次的抽象表示, 来隐藏实际实现的复杂性
- |- 虚拟机
    |- 操作系统
    |- 进程
        |- 指令集架构
            |- 处理器
        |- 虚拟内存
            |- 主存
            |- 文件 I/O设备

####  小结

## 2. 信息的表示与处理
#### 信息存储
1. 无符号数, 有符号数, 浮点数
- 溢出
- 补码
- 浮点运算是不可结合的 

2. 信息存储
- 虚拟内存上, 非常大的字节数
- 编译器和运行时系统将存储空间划分为更可管理的单元
- 程序对象: 程序数据, 指令, 控制信息 
- 可移植性的一个方面: 使程序对不同数据类型的确切大小不敏感

3. 寻址和字节顺序
- 大小端
- 最低有效字节, 从左向右开始, 指的就是数字的高低位

4. 布尔代数
- 与, 或, 非, 异或
- 信息论领域
- 布尔环, 长度为w的位向量上的 ^, & 和 ~ 运算时, 会得到一种不同的数学形式
    a & a = a;  a^a = 0;  0^b = b;
- 位向量运算, 分别将向量的每一位进行 与或非运算
- 位向量与集合的表示
    从右向左, 位向量为1的位置, 构成集合
- 掩码 
- 逻辑运算, 移位运算
    * 逻辑右移, 填充0
    * 算术右移, 按高位值填充
    * 左移都是填充0 
    * 约定有符号数都使用算术右移, 无符号数必须是逻辑右移
    * java中 >> 表示算术移位, >>> 表示逻辑移位

#### 整数表示
1. 无符号数编码的唯一性
- 双射
2. 补码编码
- 有符号数 使用 补码形式
- 补码编码的唯一性
    * 跟无符号数的编码一致, 但是高位为符号位
    * 正数的补码跟原码一致, 负数的补码还原, 符号位不变, 其余位取反加1, (这个还原也只是为了方便人工计算值, 机器计算还是直接用补码计算)
    * 这个性质就是在计算过程中发现的, 算不上推理(我比较倾向于推理的结果, 就是得到证明的结果, 而不是靠经验得出来的结果, 这个观念得改一改)
- 补码和反码

3. 有符号数和无符号数之间的转换
- C语言中不管数值信息, 保留位模式信息, 按强转的类型解释
- 补码转无符号数
- 无符号数转补码, 两个操作反过来
- 有符号数与无符号数比较, 默认先将有符号数转换成无符号数, 这样就会出现一些奇怪的现象
    负数比0大
- INT_MIN 和 INT_MAX
    * #define INT_MIN  (-INT_MAX - 1)

4. 扩展一个数字的位表示
- 无符号数的零扩展
- 补码数的符号扩展
- 截断无符号数 与 截断补码数值

5. 注意事项
- 比较, 数传运算, 避免使用无符号数
- 无符号数可做位的集合, 没有任何数字意义时, 比较好用, 用作mask 

#### 整数运算
1. 正溢出, 负溢出
2. 加, 乘
#### 浮点数
#### 小结
1. 数据表示后续有需求再研究

## 3. 程序的机器级表示
#### 历史观点
1. IA32, X86-64(X86), i386, i486, 
2. K(10^3), M(10^6), G(10^9)
#### 程序编码
1. 机器级代码 
- ISA(Instruction Set Architecture), 指令集架构
- 程序计数器(PC) %rip 给出要执行的下一条指令在内存中的地址
- C语言中的数据类型, 在机器代码中用一组连续的字节来表示, 不区分有无符号, 指针类型, 指针和整数
- x86-64的指令长度从1到15个字节不等, 常用的字节少, 不常用的字节多
- 反汇编器, 直接根据机器指令码序列来确定汇编代码, 与GCC编译出来的有差译, 但是不影响阅读
- ATT(AT&T) 与 Intel 汇编代码格式
    默认使用 ATT, Intel的编码代码比对学习, 多位操作数, 顺序不一致
- 

#### 数据格式
1.  汇编代码后缀
- 字节:b, 字:w, 双字:l, 四字:q, 单精度:s, 双精度:l
    双字和双精度都是l, 不会产生歧义, 因为机器指令和寄存器不同

#### 访问信息
1. 通用目的寄存器
- 16位(%ax-%bp), 32位(%eax-%ebp), 64位(%rax-%rbp, %r8-%r15)
2. 操作数指示符
- 立即数 ($), 寄存器(R[ra]), 内存引用(Mb[Addr])
- 寻址模式: 立即数(Imm), 寄存器(rb), 绝对, 间接, 基址+偏移量, 变址(Imm + R[rb] + R[ri]), 比例变址
- 数据传送指令: mov, 内存/寄存器 -> 寄存器, 目的大于源
    * 零扩展数据传送指令 zbw, zbl, zwl, zbq, zwq
    * 符号扩展数据传送指令 sbw, sbl, swl, sbq, slq, cltq
- 压入和弹出栈数据
    pushq
    popq
#### 算数和逻辑操作
0. 操作数
- 立即数, 寄存器, 内存地址
- 立即数不可作为目的操作数
- 内存地址作为目的操作数时, 处理器必须从内存读出值, 执行操作, 再将结果写回内存

1. 加载有效地址
- leaq S,D 
    D <- &S
    目的操作数必须是一个寄存器
    movq 的变形, 但是并没有引用内存, 而是直接将有效地址写入目的操作数(相当于指针级别的操作咯)

2. 一元操作
- INC D
- DEC D
- NEG D
- NOT D

3. 二元操作
- ADD S, D
    D <- D+S

- SUB, IMUL, XOR, OR, AND
    同上
    imul 两个操作数时, 64位乘积, 一个操作数时, 128位乘积, %rdx 高64位, %rax 低64位
    
- 第二个操作数同时作为目的操作数

4. 移位
- SAL k,D 
    D <- D << k
- SHL, 等同于 SAL
- SAR k,D
    算术右移
- SHR k,d 
    逻辑右移
- 目的操作数为 立即数或寄存器
    寄存器只能使用 %cl
    salb 移7位, salw 移15位, sall 移31位, salq 移63位

#### 控制
> 已知什么
    * if, swith, for, while, do while 在高级语言的表现
    * 关键是看完本章, 竟然有些不知道要学什么
    * 看得多, 没有记录, 恐慌! 看得少, 不知道该写什么, 烦躁! 怎么维持这个平衡
> 要学什么
    * 对应的底层实现, 要学C语言与汇编的互译
1. 条件码 
- 条件码寄存器, CF(进位标志), ZF(零标志), SF(符号标志), OF(溢出标志)
    * leaq不改变任何条件码, 它用来进行地址计算
    * 算数和逻辑操作指令都会设置条件码
- CMP, TEST
    * CMP S1, S2  =>  S2 - S1, 与SUB指令行为一致
    * TEST S1, S2  => S1 & S2, 与AND指令行为一致, 其中一个操作数是一个掩码, 用来指示哪些位应该被测试
    * CMP, TEST 只设置条件码, 不改变任何其他寄存器

2. 访问条件码: 
- 根据条件码的某种组合, 将一个字节设置0 或 1
- 可以条件跳转到程序的某个其他部分
- 可以有条件地传送数据

- SET (CMP + SET 相当于 if的效果)
    * 就是访问条件码的方式一
    * 指令的后缀表示条件, 而不是大小, >, >=, <, <= 这几种关系, 分为有符号和无符号
    * 有符号就是补码表示, 可以反推出数据类型
    * 同义名
        > 一个机器指令有多个名称
    * 通用指令
        > 等于 sete(setz), 不等于 setne(setnz)
          负数 sets, 非负数 setns
    * 有符号比较
        > 大于 setg(setnle), 大于等于 setge(setnl), 小于 setl(setnge), 小于等于 setle(setng)
    * 无符号比较 above, below
        > 大于 seta(setnbe), 大于等于 setae(setnb), 小于 setb(setnae), 小于等于 setbe(setna)
    * 无符号比较使用的是进标志和零标志组合 

3. 跳转指令
- jmp 
    * 无条件跳转
    * 直接跳转: 跳转目标作为指令编码的一部分  jmp .L1
    * 间接跳转: 跳转目标从寄存器或内存中读出  jmp *(%rax)
- 有条件跳转
    * je, jne 相等/不相等
    * js, jns 负数/非负数
    * jg, jge, jl, jle, 有符号
    * ja, jae, jb, jbe, 无符号
    * 也是根据标志码作为条件判断, 计算指令,CMP, TEST指令, 都会更新标志码
    * 有条件跳转的 相对地址是在下一条指令的基础上加减, 仅仅是在下一条, 里面的逻辑也不合理呀? 但是练习题确是这样
- 跳转指令的编码
    * PC相对的(PC-relative)
    * 绝对地址
    * rep, repz
        + AMD的说法: 当ret指令通过跳转指令到达时, 处理器不能正确预测ret指令的目的, 加入rep能使代码在AMD上运行的更快之外, 不会改变代码的其他(ret)行为
- 用条件传送来实现条件分支
    * 条件传送指令, 更符合现代处理器的性能特性
    * cmov(compare move), 也是根据条件码的值来操作, 只有满足指定条件时, 才会被复制到目的寄存器中
    * 汇编器可以从目标寄存器的名字推断出条件传送指令的操作数长度, 所以对所有的操作数长度, 可以使用同一个的指令名字, 不需要l,w,q来区分
    * cmove/cmovne S,R
    * cmoves/cmovens S,R
    * cmovg/cmova cmovege/cmovae S,R
    * cmovl/cmovle cmovb/cmovbe S,R
    * 条件数据传送提供了一种用条件控制转移来实现条件操作的替代策略. 它们只能用于非常受限的情况, 但是这些情况还是非常常见的, 而且与现代处理器的运行方式更契合
    * 预测分支计算量, 计算量的消耗是否比预测错误的性能处罚大, 这个点正是疑问点, 已经被考虑了, 一般条件里只是简单的一条指令, 适合用于条件传送指令, 由于这种情况非常常见, 所以, 条件传送指令还是有提升性能的特点的
    * 这里也是程序性能优化的地方, 程序员与编译器配合, 尽量不在分支中做过多的计算
    * 条件跳转更通用
- 循环
    * while, do-while, 较高优化等级的编译器(GCC) 加选项 -O1 会将 while 翻译成 do-while, 这说明, do-while的形式更高效?
    * 跳转到中间的翻译方法, guarded-do翻译方法
    * for循环
- switch
    * 跳转表, 每个元素都是一个指向代码位置的指针
    * switch的反汇编有一些难度: 
    * 如何分析跳转表与真实代码的对应关系
    * 跳转表的顺序就是按case值的顺序对应, 根据cmp与ja 判断case值范围, 与default 标签, 跳转表中对应的default跳转即为缺失的case值

#### 过程
0. 传递控制, 伟递数据, 分配和释放内存
1. 运行时栈
- 栈帧

2. 转移控制
- call Q
- M, T, F, L 代表什么含义? 定义函数的首字母
- %rdi(参数1), %rsi(参数2), %rax(返回值), %rsp(栈指针)
- 指令PC如何更新? 就是内存地址
- 各寄存器的值, 是在当条指令执行完毕后才会更新
- 从这里也可以理解, 为何C/C++中要先声明函数定义, 再使用了, 就是要将子函数放在前面, main函数放在最下面, 这样更容易转移控制

3. 数据传送
- x86-64中,大部分的数传传递是通过寄存器实现的
- 寄存器最多可传6个整型, %rdi, %rsi, %rdx, %rcx, %r8, %r9, 大于6个就需要通过栈来传递
- movslq 带符号位扩展, 由4->8, 扩展位置0

4. 栈的上局部存储
- 有些时候, 局部数据必须存放在内存中
    * 寄存器不足够存放本地数据.
    * 对一个局部变量使用地址运算符 &, 因此必须能够为它产生一个地址.
    * 某些局部变量是数组或结构, 因此必须能够通过数组或结构引用被访问到.

5. 寄存器中的局部存储空间
- 调用者保存寄存器, 根据惯例 %rbx, %rbp 和 %r12 ~ %r15, 

6. 递归过程
- 正常的函数调用

#### 数组的分配和访问
1. 基本原则
- 元素大小, 整个数组大小, 元素i的位置

2. 指针运算
- 同上, lea 只是针对地址计算, 不改变寄存器和标志位的值

3. 嵌套的数组
- 连续的数组 T D[R][C];
- 行优先, 列其次, 按公式 &D[i][j] = Xd + L(C*i + j)

4. 定长数组
- 定义需指明大小

5. 变长数组
- 可以使用表达式表示数组, 在分配内存的时候, 根据表达式的值, 分配数组大小
- 原始是不够时, 再moalloc

#### 异数的数据结构
1. 结构(struct)
- 结构嵌套
- 数据对齐
- 总大小为各个字段大小总合
- struct中的数据类型本就是引用, 编译成指令, 在寄存器中存的是地址
- struct 嵌套struct, 内部的struct也会无效, 所有的类型都提到最外层struct, 内部的struct只是在编译器中占用一个符号引用
    此时的内存布局作为一个sturct的对齐方式排列, 嵌套在union中

2. 联合
- 总大小为最大值大小
- struct 在 union中, 按union的内存布局来分配, 在这里可理解, struct 只是相当于一个符号引用, 只在编译器级别占用一个符号, 并不在指令中有内存分配
- 以最大数据类型的大小分配一块内存, 然后可以按照union中的任何类型来访问这块内存, 这个特性猛一看上去, 很棒, 可以将double类型数据按long读出来, 但是应用场景并不多, 而且容易造成误解

3. 数据对齐
- 方便硬件接口的设计, 访问更高效, 但是对不对齐, 都能正常工作
- 对齐的原则: 任何K字节的基本对象的地址必须是K的倍数, 1, 2, 4, 8 
    * 以相邻的数据类型大小较大的作为对齐的标准, 满足大的对齐, 一定满足较小的对齐
- 在编译器层, 也得注意数据对齐, 这是与程序的一个约定

#### 在机器级程序中将控制与数据结合起来
1. 理解指针
- 每个指针都对应一个类型
    指针类型不是机器代码中的一部分, 是C语言提供的一种抽象, 帮助程序员避免寻址错误
- 每个指针都有一个值
    特殊的 NULL(0) 值表示该指针没有指向任何地方
- 指针用 '&' 运算符创建
- '*' 操作符用于间接引用指针
- 数组与指针紧密联系
- 将指针从一种类型强制转换成另一种类型, 只改变它的类型, 而不改变它的值
- 指针也可以指向函数
    函数指针的值是该函数机器代码表示中第一条指令的地址

2. 内存越界引用和缓冲区溢出
- 练习题346(p233)看不太明白, 理解缓冲区溢出攻击大概是个什么意思
- 栈随机化
    * 栈的位置在程序每次运行时都有变化 
    * 程序开始时, 在栈上分配指定字节数量的空间
    * 地址空间布局随机化(ASLR)
    * 空操作雪橇 (nop sled), nop 只会让程序计数器加一, 没有其他效果

- 栈破坏检测
    * 设置canary
    * %fs:40 段地址读取

- 限制可执行代码区域
    * 已经硬件支持, NX(No-Execute)

- 三种最常见的机制, 不需要程序员做任何特殊努力, 带来的性能代价都非常小, 甚至没有

3. 支持变长帧
- %rbp, base pointer, 帧指针
- leave指令, 将帧指针恢复到它之前的值
    等价于 movq %rbp, %rsp
          popq %rbp

#### 浮点代码
 浮点相关, 暂时只作了解
1. 寄存器 
- YMM寄存器: %ymm0 ~ %ymm15
- XMM寄存器: %xmm0 ~ %xmm15

2. 浮点传送和转换操作
- 单精度: vmovss, vmovsd, vmovaps, vmovapd
    Single, Double, Aligned P(?) Single, Aligned P(?) Double
- 双精度: vcvttss2si, vcvttsd2si, vcvttss2siq, vcvttsd2siq
         vcvtsi2ss, vcvtsi2sd, vcvtsi2ssq, vcvtsi2sdq
3. 浮点运算   
- vaddss, vaddsd
- 

4. 在浮点代码中使用位级操作
- vxorps, vandps

5. 比较操作
- ucomiss, ucomisd

## 优化程序性能

    感觉已经有些基础积累, 本章是否可快速通过? 
    程序性能优化从哪几个方面? 
    有何常用手段? 
    性能的评价标准? 
    与语法设计有何关联呢?
    通过语法设计, 性能标准, 找出语言的通用性与特性, 不同领域不同应用.

1. 优化编译器的能力和局限
- 编译器层面的优化, 放在编译指令上, 还是代码实现上, 一般是两者结合
    * 编译指令优化 -Og, -O1, -O2, -O3 默认-O2级别优化
- 编译器的能力有哪些局限?
    * 妨碍优化的因素
        不能确认指针是否指向同一个位置
        函数的多次调用(编译器会假设最糟糕情况, 并保持所有的函数调用不变)
    * GCC只尝试单个文件中定义的函数内联
    * 内联减少程序调用, 但是会增加代码长度, 内联需要注意函数无负作用, 内联的操作相当于define的替换

2. 表示程序的性能
- 程序的性能点体现在哪些地方?
    * 每元素的周期数(Cycles Per Element, CPE)
- 最小二乘拟合
    * y = mx +b, 对E(m,b) 中 m,b分别求导, 导函数设置为0, 求得m,b的算法
    * 最接近于数据代表的 x-y趋势

4. 消除循环的低效率
- 循环哪里会引起低效率
- 不会变的值, 不用在循环里计算多次, 如容器的大小

5. 减少过程调用
- 过程调用为何要减少, 哪些地方增加了开销?
    * 存栈, 分配内存, 恢复栈
    * 妨碍大多数形式的程序优化

6. 消除不必要的内存引用
- 内存引用会引起效率? 寻址上吗?
    * 从内存中读写要比访问寄存器慢, 所以, 临时局部变量很有必要
    * 访问即寻址

7. 理解现代处理器
- 现在处理器需要学习的点有哪些?
    * 指令级并行
    * 吞吐量界限, 是程序性能的终极界限
    * 超标量, 乱序的(out-of-order),能更好地达到更高的指令级并行度
    * 高速缓存
    * 分支预测技术

- concept
    * 投机执行(speculative execution)
    * 分支预测(branch prediction)
    * 指令译码逻辑
    * 寄存器文件(寄存器本身?)
    * 退役单元(retirement unit)
    * 寄存器重命名(register renaming)
    * 延迟(lantency), 表示完成运算所需要的总时间
    * 发射时间(issue time), 表示两个连续的同类型运算之阐需要的最小时钟周期数
    * 最大吞吐量, 定义为发射时间的倒数
    * 容量(capacity), 表示能够执行该运算的功能单元的数量.

8. 循环展开
- 循环展开, 并不是由C循环翻译成汇编的方式
- a. 减少不直接有助于程序结果的操作的数量, 如循环索引计算和条件分支
- b. 减少整个计算中关键路径上的操作数量
- GCC 优化等级3或更高等级, 就会执行循环展开

9. 提高并行性
- 多线程编程会提高性能, 多线程编程也会增加开销, 平衡点在哪里?
- a. 多个累积变量
- b. 

10. 优化合并代码的结果小结
- 合并代码指得是什么? 为何这里有个小结
    * 重新结合变换， 如将循环二次遍历合为一次, 能够减少关键路径上操作的数量
    * 用向量指令达到更高的并行度
    * 多项优化技术, 非常程式化的方式

11. 一些限制因素
- 限制因素有哪些? 硬件层面, 软件层面, 客观人力?
- 寄存器溢出
    * x86-64 有足够多的寄存器， 大多数循环在出现寄存器溢出之前就将达到吞吐量限制
- 分支预测和预测错误惩罚

12. 理解内存性能
- 内存性能指标是什么?
    * 高速缓存区
    * 加载的性能, 依赖于流水线的能力， 也依赖于加载单元的延迟
    * 存储的性能

- 有何优化手段
    * 

13. 应用: 性能提高技术
- 实际应用
- 高级设计. 为遇到的问题选择适当的数据结构和算法
- 基本编码原则.
    * 避免优化限制的因素， 依靠编译器才能产生高效的代码
    * 消除不必要的内存引用. 引入临时变量来保存中间结果。 
- 低级优化. 结构化代码以利用硬件功能 
    * 展开循环, 降低开销
    * 通过使用多个累加变量和重新结合等技术， 找到方法提高指令并行
    * 用功能性的风格重写条件操作（三目运算符？：）， 使得编译器采用条件传送数据

14. 确认和消除性能瓶颈
- 实战? 
- 代码剖析程序( code profiler)
    * gprof 工具
- Amdahl定律

15. 小结
- 性能优化方面:
    1. 主要目的就是减少所有指令执行的时钟周期
    2. 一个是 寄存器=堆栈 >= 内存 的访问速率
    3. 循环里减少计算量, 减少函数调用
    4. 函数会妨碍编译器优化, 编译器对于函数的优化, 都是以最糟糕的情况来假设, 这样稳妥保证不出错

## 链接
1. 

## 
## 
## 
## 
## 